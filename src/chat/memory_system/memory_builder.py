# -*- coding: utf-8 -*-
"""
è®°å¿†æ„å»ºæ¨¡å—
ä»å¯¹è¯æµä¸­æå–é«˜è´¨é‡ã€ç»“æ„åŒ–è®°å¿†å•å…ƒ
"""

import re
import time
import orjson
from typing import Dict, List, Optional, Tuple, Any, Set
from datetime import datetime
from dataclasses import dataclass
from enum import Enum

from src.common.logger import get_logger
from src.llm_models.utils_model import LLMRequest
from src.chat.memory_system.memory_chunk import (
    MemoryChunk, MemoryType, ConfidenceLevel, ImportanceLevel,
    ContentStructure, MemoryMetadata, create_memory_chunk
)

logger = get_logger(__name__)


class ExtractionStrategy(Enum):
    """æå–ç­–ç•¥"""
    LLM_BASED = "llm_based"           # åŸºäºLLMçš„æ™ºèƒ½æå–
    RULE_BASED = "rule_based"         # åŸºäºè§„åˆ™çš„æå–
    HYBRID = "hybrid"                 # æ··åˆç­–ç•¥


@dataclass
class ExtractionResult:
    """æå–ç»“æœ"""
    memories: List[MemoryChunk]
    confidence_scores: List[float]
    extraction_time: float
    strategy_used: ExtractionStrategy


class MemoryBuilder:
    """è®°å¿†æ„å»ºå™¨"""

    def __init__(self, llm_model: LLMRequest):
        self.llm_model = llm_model
        self.extraction_stats = {
            "total_extractions": 0,
            "successful_extractions": 0,
            "failed_extractions": 0,
            "average_confidence": 0.0
        }

    async def build_memories(
        self,
        conversation_text: str,
        context: Dict[str, Any],
        user_id: str,
        timestamp: float
    ) -> List[MemoryChunk]:
        """ä»å¯¹è¯ä¸­æ„å»ºè®°å¿†"""
        start_time = time.time()

        try:
            logger.debug(f"å¼€å§‹ä»å¯¹è¯æ„å»ºè®°å¿†ï¼Œæ–‡æœ¬é•¿åº¦: {len(conversation_text)}")

            # é¢„å¤„ç†æ–‡æœ¬
            processed_text = self._preprocess_text(conversation_text)

            # ç¡®å®šæå–ç­–ç•¥
            strategy = self._determine_extraction_strategy(processed_text, context)

            # æ ¹æ®ç­–ç•¥æå–è®°å¿†
            if strategy == ExtractionStrategy.LLM_BASED:
                memories = await self._extract_with_llm(processed_text, context, user_id, timestamp)
            elif strategy == ExtractionStrategy.RULE_BASED:
                memories = self._extract_with_rules(processed_text, context, user_id, timestamp)
            else:  # HYBRID
                memories = await self._extract_with_hybrid(processed_text, context, user_id, timestamp)

            # åå¤„ç†å’ŒéªŒè¯
            validated_memories = self._validate_and_enhance_memories(memories, context)

            # æ›´æ–°ç»Ÿè®¡
            extraction_time = time.time() - start_time
            self._update_extraction_stats(len(validated_memories), extraction_time)

            logger.info(f"âœ… æˆåŠŸæ„å»º {len(validated_memories)} æ¡è®°å¿†ï¼Œè€—æ—¶ {extraction_time:.2f}ç§’")
            return validated_memories

        except Exception as e:
            logger.error(f"âŒ è®°å¿†æ„å»ºå¤±è´¥: {e}", exc_info=True)
            self.extraction_stats["failed_extractions"] += 1
            return []

    def _preprocess_text(self, text: str) -> str:
        """é¢„å¤„ç†æ–‡æœ¬"""
        # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
        text = re.sub(r'\s+', ' ', text.strip())

        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œä½†ä¿ç•™åŸºæœ¬æ ‡ç‚¹
        text = re.sub(r'[^\w\s\u4e00-\u9fffï¼Œã€‚ï¼ï¼Ÿã€ï¼›ï¼š""''ï¼ˆï¼‰ã€ã€‘]', '', text)

        # æˆªæ–­è¿‡é•¿çš„æ–‡æœ¬
        if len(text) > 2000:
            text = text[:2000] + "..."

        return text

    def _determine_extraction_strategy(self, text: str, context: Dict[str, Any]) -> ExtractionStrategy:
        """ç¡®å®šæå–ç­–ç•¥"""
        text_length = len(text)
        has_structured_data = any(key in context for key in ["structured_data", "entities", "keywords"])
        message_type = context.get("message_type", "normal")

        # çŸ­æ–‡æœ¬ä½¿ç”¨è§„åˆ™æå–
        if text_length < 50:
            return ExtractionStrategy.RULE_BASED

        # åŒ…å«ç»“æ„åŒ–æ•°æ®ä½¿ç”¨æ··åˆç­–ç•¥
        if has_structured_data:
            return ExtractionStrategy.HYBRID

        # ç³»ç»Ÿæ¶ˆæ¯æˆ–å‘½ä»¤ä½¿ç”¨è§„åˆ™æå–
        if message_type in ["command", "system"]:
            return ExtractionStrategy.RULE_BASED

        # é»˜è®¤ä½¿ç”¨LLMæå–
        return ExtractionStrategy.LLM_BASED

    async def _extract_with_llm(
        self,
        text: str,
        context: Dict[str, Any],
        user_id: str,
        timestamp: float
    ) -> List[MemoryChunk]:
        """ä½¿ç”¨LLMæå–è®°å¿†"""
        try:
            prompt = self._build_llm_extraction_prompt(text, context)

            response, _ = await self.llm_model.generate_response_async(
                prompt, temperature=0.3
            )

            # è§£æLLMå“åº”
            memories = self._parse_llm_response(response, user_id, timestamp, context)

            return memories

        except Exception as e:
            logger.error(f"LLMæå–å¤±è´¥: {e}")
            return []

    def _extract_with_rules(
        self,
        text: str,
        context: Dict[str, Any],
        user_id: str,
        timestamp: float
    ) -> List[MemoryChunk]:
        """ä½¿ç”¨è§„åˆ™æå–è®°å¿†"""
        memories = []

        # è§„åˆ™1: æ£€æµ‹ä¸ªäººä¿¡æ¯
        personal_info = self._extract_personal_info(text, user_id, timestamp, context)
        memories.extend(personal_info)

        # è§„åˆ™2: æ£€æµ‹åå¥½ä¿¡æ¯
        preferences = self._extract_preferences(text, user_id, timestamp, context)
        memories.extend(preferences)

        # è§„åˆ™3: æ£€æµ‹äº‹ä»¶ä¿¡æ¯
        events = self._extract_events(text, user_id, timestamp, context)
        memories.extend(events)

        return memories

    async def _extract_with_hybrid(
        self,
        text: str,
        context: Dict[str, Any],
        user_id: str,
        timestamp: float
    ) -> List[MemoryChunk]:
        """æ··åˆç­–ç•¥æå–è®°å¿†"""
        all_memories = []

        # é¦–å…ˆä½¿ç”¨è§„åˆ™æå–
        rule_memories = self._extract_with_rules(text, context, user_id, timestamp)
        all_memories.extend(rule_memories)

        # ç„¶åä½¿ç”¨LLMæå–
        llm_memories = await self._extract_with_llm(text, context, user_id, timestamp)

        # åˆå¹¶å’Œå»é‡
        final_memories = self._merge_hybrid_results(all_memories, llm_memories)

        return final_memories

    def _build_llm_extraction_prompt(self, text: str, context: Dict[str, Any]) -> str:
        """æ„å»ºLLMæå–æç¤º"""
        current_date = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        chat_id = context.get("chat_id", "unknown")
        message_type = context.get("message_type", "normal")

        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è®°å¿†æå–ä¸“å®¶ã€‚è¯·ä»ä»¥ä¸‹å¯¹è¯ä¸­ä¸»åŠ¨è¯†åˆ«å¹¶æå–æ‰€æœ‰å¯èƒ½é‡è¦çš„ä¿¡æ¯ï¼Œç‰¹åˆ«æ˜¯åŒ…å«ä¸ªäººäº‹å®ã€äº‹ä»¶ã€åå¥½ã€è§‚ç‚¹ç­‰è¦ç´ çš„å†…å®¹ã€‚

å½“å‰æ—¶é—´: {current_date}
èŠå¤©ID: {chat_id}
æ¶ˆæ¯ç±»å‹: {message_type}

å¯¹è¯å†…å®¹:
{text}

## ğŸ¯ é‡ç‚¹è®°å¿†ç±»å‹è¯†åˆ«æŒ‡å—

### 1. **ä¸ªäººäº‹å®** (personal_fact) - é«˜ä¼˜å…ˆçº§è®°å¿†
**åŒ…æ‹¬ä½†ä¸é™äºï¼š**
- åŸºæœ¬ä¿¡æ¯ï¼šå§“åã€å¹´é¾„ã€èŒä¸šã€å­¦æ ¡ã€ä¸“ä¸šã€å·¥ä½œåœ°ç‚¹
- ç”Ÿæ´»çŠ¶å†µï¼šä½å€ã€ç”µè¯ã€é‚®ç®±ã€ç¤¾äº¤è´¦å·
- èº«ä»½ç‰¹å¾ï¼šç”Ÿæ—¥ã€æ˜Ÿåº§ã€è¡€å‹ã€å›½ç±ã€è¯­è¨€èƒ½åŠ›
- å¥åº·ä¿¡æ¯ï¼šèº«ä½“çŠ¶å†µã€ç–¾ç—…å²ã€è¯ç‰©è¿‡æ•ã€è¿åŠ¨ä¹ æƒ¯
- å®¶åº­æƒ…å†µï¼šå®¶åº­æˆå‘˜ã€å©šå§»çŠ¶å†µã€å­å¥³ä¿¡æ¯ã€å® ç‰©ä¿¡æ¯

**åˆ¤æ–­æ ‡å‡†ï¼š** æ¶‰åŠä¸ªäººèº«ä»½å’Œç”Ÿæ´»çš„é‡è¦ä¿¡æ¯ï¼Œéƒ½åº”è¯¥è®°å¿†

### 2. **äº‹ä»¶** (event) - é«˜ä¼˜å…ˆçº§è®°å¿†
**åŒ…æ‹¬ä½†ä¸é™äºï¼š**
- é‡è¦æ—¶åˆ»ï¼šç”Ÿæ—¥èšä¼šã€æ¯•ä¸šå…¸ç¤¼ã€å©šç¤¼ã€æ—…è¡Œ
- æ—¥å¸¸æ´»åŠ¨ï¼šä¸Šç­ã€ä¸Šå­¦ã€çº¦ä¼šã€çœ‹ç”µå½±ã€åƒé¥­
- ç‰¹æ®Šç»å†ï¼šè€ƒè¯•ã€é¢è¯•ã€ä¼šè®®ã€æ¬å®¶ã€è´­ç‰©
- è®¡åˆ’å®‰æ’ï¼šçº¦ä¼šã€ä¼šè®®ã€æ—…è¡Œã€æ´»åŠ¨

**åˆ¤æ–­æ ‡å‡†ï¼š** æ¶‰åŠæ—¶é—´åœ°ç‚¹çš„å…·ä½“æ´»åŠ¨å’Œç»å†ï¼Œéƒ½åº”è¯¥è®°å¿†

### 3. **åå¥½** (preference) - é«˜ä¼˜å…ˆçº§è®°å¿†
**åŒ…æ‹¬ä½†ä¸é™äºï¼š**
- é¥®é£Ÿåå¥½ï¼šå–œæ¬¢çš„é£Ÿç‰©ã€é¤å…ã€å£å‘³ã€ç¦å¿Œ
- å¨±ä¹å–œå¥½ï¼šå–œæ¬¢çš„ç”µå½±ã€éŸ³ä¹ã€æ¸¸æˆã€ä¹¦ç±
- ç”Ÿæ´»ä¹ æƒ¯ï¼šä½œæ¯æ—¶é—´ã€è¿åŠ¨æ–¹å¼ã€è´­ç‰©ä¹ æƒ¯
- æ¶ˆè´¹åå¥½ï¼šå“ç‰Œå–œå¥½ã€ä»·æ ¼æ•æ„Ÿåº¦ã€è´­ç‰©åœºæ‰€
- é£æ ¼åå¥½ï¼šæœè£…é£æ ¼ã€è£…ä¿®é£æ ¼ã€é¢œè‰²å–œå¥½

**åˆ¤æ–­æ ‡å‡†ï¼š** ä»»ä½•è¡¨è¾¾"å–œæ¬¢"ã€"ä¸å–œæ¬¢"ã€"ä¹ æƒ¯"ã€"ç»å¸¸"ç­‰åå¥½çš„å†…å®¹ï¼Œéƒ½åº”è¯¥è®°å¿†

### 4. **è§‚ç‚¹** (opinion) - é«˜ä¼˜å…ˆçº§è®°å¿†
**åŒ…æ‹¬ä½†ä¸é™äºï¼š**
- è¯„ä»·çœ‹æ³•ï¼šå¯¹äº‹ç‰©çš„è¯„ä»·ã€æ„è§ã€å»ºè®®
- ä»·å€¼åˆ¤æ–­ï¼šè®¤ä¸ºä»€ä¹ˆé‡è¦ã€ä»€ä¹ˆä¸é‡è¦
- æ€åº¦ç«‹åœºï¼šæ”¯æŒã€åå¯¹ã€ä¸­ç«‹çš„æ€åº¦
- æ„Ÿå—åé¦ˆï¼šå¯¹ç»å†çš„æ„Ÿå—ã€åé¦ˆ

**åˆ¤æ–­æ ‡å‡†ï¼š** ä»»ä½•è¡¨è¾¾ä¸»è§‚çœ‹æ³•å’Œæ€åº¦çš„å†…å®¹ï¼Œéƒ½åº”è¯¥è®°å¿†

### 5. **å…³ç³»** (relationship) - ä¸­ç­‰ä¼˜å…ˆçº§è®°å¿†
**åŒ…æ‹¬ä½†ä¸é™äºï¼š**
- äººé™…å…³ç³»ï¼šæœ‹å‹ã€åŒäº‹ã€å®¶äººã€æ‹äººçš„å…³ç³»çŠ¶æ€
- ç¤¾äº¤äº’åŠ¨ï¼šä¸ä»–äººçš„äº’åŠ¨ã€äº¤æµã€åˆä½œ
- ç¾¤ä½“å½’å±ï¼šæ‰€å±å›¢é˜Ÿã€ç»„ç»‡ã€ç¤¾ç¾¤

### 6. **æƒ…æ„Ÿ** (emotion) - ä¸­ç­‰ä¼˜å…ˆçº§è®°å¿†
**åŒ…æ‹¬ä½†ä¸é™äºï¼š**
- æƒ…ç»ªçŠ¶æ€ï¼šå¼€å¿ƒã€éš¾è¿‡ã€ç”Ÿæ°”ã€ç„¦è™‘ã€å…´å¥‹
- æƒ…æ„Ÿå˜åŒ–ï¼šæƒ…ç»ªçš„è½¬å˜ã€åŸå› å’Œç»“æœ

### 7. **ç›®æ ‡** (goal) - ä¸­ç­‰ä¼˜å…ˆçº§è®°å¿†
**åŒ…æ‹¬ä½†ä¸é™äºï¼š**
- è®¡åˆ’å®‰æ’ï¼šçŸ­æœŸè®¡åˆ’ã€é•¿æœŸç›®æ ‡
- æ„¿æœ›æœŸå¾…ï¼šæƒ³è¦å®ç°çš„äº‹æƒ…ã€æœŸæœ›çš„ç»“æœ

## ğŸ“ è®°å¿†æå–åŸåˆ™

### âœ… ç§¯ææå–åŸåˆ™ï¼š
1. **å®å¯é”™è®°ï¼Œä¸å¯é—æ¼** - å¯¹äºå¯èƒ½çš„ä¸ªäººä¿¡æ¯ä¼˜å…ˆè®°å¿†
2. **æŒç»­è¿½è¸ª** - ç›¸åŒä¿¡æ¯çš„å¤šæ¬¡æåŠè¦å¼ºåŒ–è®°å¿†
3. **ä¸Šä¸‹æ–‡å…³è”** - ç»“åˆå¯¹è¯èƒŒæ™¯ç†è§£ä¿¡æ¯é‡è¦æ€§
4. **ç»†èŠ‚ä¸°å¯Œ** - è®°å½•å…·ä½“çš„ç»†èŠ‚å’Œæè¿°

### ğŸ•’ æ—¶é—´å¤„ç†åŸåˆ™ï¼ˆé‡è¦ï¼‰ï¼š
1. **ç»å¯¹æ—¶é—´è¦æ±‚** - æ¶‰åŠæ—¶é—´çš„è®°å¿†å¿…é¡»ä½¿ç”¨ç»å¯¹æ—¶é—´ï¼ˆå¹´æœˆæ—¥ï¼‰
2. **ç›¸å¯¹æ—¶é—´è½¬æ¢** - å°†"æ˜å¤©"ã€"åå¤©"ã€"ä¸‹å‘¨"ç­‰ç›¸å¯¹æ—¶é—´è½¬æ¢ä¸ºå…·ä½“æ—¥æœŸ
3. **æ—¶é—´æ ¼å¼è§„èŒƒ** - ä½¿ç”¨"YYYY-MM-DD"æ ¼å¼è®°å½•æ—¥æœŸ
4. **å½“å‰æ—¶é—´å‚è€ƒ** - å½“å‰æ—¶é—´ï¼š{current_date}ï¼ŒåŸºäºæ­¤è®¡ç®—ç›¸å¯¹æ—¶é—´

**ç›¸å¯¹æ—¶é—´è½¬æ¢ç¤ºä¾‹ï¼š**
- "æ˜å¤©" â†’ "2024-09-30"
- "åå¤©" â†’ "2024-10-01"
- "ä¸‹å‘¨" â†’ "2024-10-07"
- "ä¸‹ä¸ªæœˆ" â†’ "2024-10-01"
- "æ˜å¹´" â†’ "2025-01-01"

### ğŸ¯ é‡è¦æ€§ç­‰çº§æ ‡å‡†ï¼š
- **4åˆ† (å…³é”®)**ï¼šä¸ªäººæ ¸å¿ƒä¿¡æ¯ï¼ˆå§“åã€è”ç³»æ–¹å¼ã€é‡è¦æ—¥æœŸï¼‰
- **3åˆ† (é«˜)**ï¼šé‡è¦åå¥½ã€è§‚ç‚¹ã€ç»å†äº‹ä»¶
- **2åˆ† (ä¸€èˆ¬)**ï¼šä¸€èˆ¬æ€§ä¿¡æ¯ã€æ—¥å¸¸æ´»åŠ¨ã€æ„Ÿå—è¡¨è¾¾
- **1åˆ† (ä½)**ï¼šçç¢ç»†èŠ‚ã€é‡å¤ä¿¡æ¯ã€ä¸´æ—¶çŠ¶æ€

### ğŸ” ç½®ä¿¡åº¦æ ‡å‡†ï¼š
- **4åˆ† (å·²éªŒè¯)**ï¼šç”¨æˆ·æ˜ç¡®ç¡®è®¤çš„ä¿¡æ¯
- **3åˆ† (é«˜)**ï¼šç”¨æˆ·ç›´æ¥è¡¨è¾¾çš„æ¸…æ™°ä¿¡æ¯
- **2åˆ† (ä¸­ç­‰)**ï¼šéœ€è¦æ¨ç†æˆ–ä¸Šä¸‹æ–‡åˆ¤æ–­çš„ä¿¡æ¯
- **1åˆ† (ä½)**ï¼šæ¨¡ç³Šæˆ–ä¸å®Œæ•´çš„ä¿¡æ¯

è¾“å‡ºæ ¼å¼è¦æ±‚:
{{
    "memories": [
        {{
            "type": "è®°å¿†ç±»å‹",
            "subject": "ä¸»è¯­(é€šå¸¸æ˜¯ç”¨æˆ·)",
            "predicate": "è°“è¯­(åŠ¨ä½œ/çŠ¶æ€)",
            "object": "å®¾è¯­(å¯¹è±¡/å±æ€§)",
            "keywords": ["å…³é”®è¯1", "å…³é”®è¯2"],
            "importance": "é‡è¦æ€§ç­‰çº§(1-4)",
            "confidence": "ç½®ä¿¡åº¦(1-4)",
            "reasoning": "æå–ç†ç”±"
        }}
    ]
}}

æ³¨æ„ï¼š
1. åªæå–ç¡®å®å€¼å¾—è®°å¿†çš„ä¿¡æ¯ï¼Œä¸è¦æå–çç¢å†…å®¹
2. ç¡®ä¿æå–çš„ä¿¡æ¯å‡†ç¡®ã€å…·ä½“ã€æœ‰ä»·å€¼
3. ä½¿ç”¨ä¸»è°“å®¾ç»“æ„ç¡®ä¿ä¿¡æ¯æ¸…æ™°
4. é‡è¦æ€§ç­‰çº§: 1=ä½, 2=ä¸€èˆ¬, 3=é«˜, 4=å…³é”®
5. ç½®ä¿¡åº¦: 1=ä½, 2=ä¸­ç­‰, 3=é«˜, 4=å·²éªŒè¯

## ğŸš¨ æ—¶é—´å¤„ç†è¦æ±‚ï¼ˆå¼ºåˆ¶ï¼‰ï¼š
- **ç»å¯¹æ—¶é—´ä¼˜å…ˆ**ï¼šä»»ä½•æ¶‰åŠæ—¶é—´çš„è®°å¿†éƒ½å¿…é¡»ä½¿ç”¨ç»å¯¹æ—¥æœŸæ ¼å¼
- **ç›¸å¯¹æ—¶é—´è½¬æ¢**ï¼šé‡åˆ°"æ˜å¤©"ã€"åå¤©"ã€"ä¸‹å‘¨"ç­‰ç›¸å¯¹æ—¶é—´å¿…é¡»è½¬æ¢ä¸ºå…·ä½“æ—¥æœŸ
- **æ—¶é—´æ ¼å¼**ï¼šç»Ÿä¸€ä½¿ç”¨ "YYYY-MM-DD" æ ¼å¼
- **è®¡ç®—ä¾æ®**ï¼šåŸºäºå½“å‰æ—¶é—´ {current_date} è¿›è¡Œè½¬æ¢è®¡ç®—
"""

        return prompt

    def _parse_llm_response(
        self,
        response: str,
        user_id: str,
        timestamp: float,
        context: Dict[str, Any]
    ) -> List[MemoryChunk]:
        """è§£æLLMå“åº”"""
        memories = []

        try:
            data = orjson.loads(response)
            memory_list = data.get("memories", [])

            for mem_data in memory_list:
                try:
                    # åˆ›å»ºè®°å¿†å—
                    memory = create_memory_chunk(
                        user_id=user_id,
                        subject=mem_data.get("subject", user_id),
                        predicate=mem_data.get("predicate", ""),
                        obj=mem_data.get("object", ""),
                        memory_type=MemoryType(mem_data.get("type", "contextual")),
                        chat_id=context.get("chat_id"),
                        source_context=mem_data.get("reasoning", ""),
                        importance=ImportanceLevel(mem_data.get("importance", 2)),
                        confidence=ConfidenceLevel(mem_data.get("confidence", 2))
                    )

                    # æ·»åŠ å…³é”®è¯
                    keywords = mem_data.get("keywords", [])
                    for keyword in keywords:
                        memory.add_keyword(keyword)

                    memories.append(memory)

                except Exception as e:
                    logger.warning(f"è§£æå•ä¸ªè®°å¿†å¤±è´¥: {e}, æ•°æ®: {mem_data}")
                    continue

        except Exception as e:
            logger.error(f"è§£æLLMå“åº”å¤±è´¥: {e}, å“åº”: {response}")

        return memories

    def _extract_personal_info(
        self,
        text: str,
        user_id: str,
        timestamp: float,
        context: Dict[str, Any]
    ) -> List[MemoryChunk]:
        """æå–ä¸ªäººä¿¡æ¯"""
        memories = []

        # å¸¸è§ä¸ªäººä¿¡æ¯æ¨¡å¼
        patterns = {
            r"æˆ‘å«(\w+)": ("is_named", {"name": "$1"}),
            r"æˆ‘ä»Šå¹´(\d+)å²": ("is_age", {"age": "$1"}),
            r"æˆ‘æ˜¯(\w+)": ("is_profession", {"profession": "$1"}),
            r"æˆ‘ä½åœ¨(\w+)": ("lives_in", {"location": "$1"}),
            r"æˆ‘çš„ç”µè¯æ˜¯(\d+)": ("has_phone", {"phone": "$1"}),
            r"æˆ‘çš„é‚®ç®±æ˜¯(\w+@\w+\.\w+)": ("has_email", {"email": "$1"}),
        }

        for pattern, (predicate, obj_template) in patterns.items():
            match = re.search(pattern, text)
            if match:
                obj = obj_template
                for i, group in enumerate(match.groups(), 1):
                    obj = {k: v.replace(f"${i}", group) for k, v in obj.items()}

                memory = create_memory_chunk(
                    user_id=user_id,
                    subject=user_id,
                    predicate=predicate,
                    obj=obj,
                    memory_type=MemoryType.PERSONAL_FACT,
                    chat_id=context.get("chat_id"),
                    importance=ImportanceLevel.HIGH,
                    confidence=ConfidenceLevel.HIGH
                )

                memories.append(memory)

        return memories

    def _extract_preferences(
        self,
        text: str,
        user_id: str,
        timestamp: float,
        context: Dict[str, Any]
    ) -> List[MemoryChunk]:
        """æå–åå¥½ä¿¡æ¯"""
        memories = []

        # åå¥½æ¨¡å¼
        preference_patterns = [
            (r"æˆ‘å–œæ¬¢(.+)", "likes"),
            (r"æˆ‘ä¸å–œæ¬¢(.+)", "dislikes"),
            (r"æˆ‘çˆ±åƒ(.+)", "likes_food"),
            (r"æˆ‘è®¨åŒ(.+)", "hates"),
            (r"æˆ‘æœ€å–œæ¬¢çš„(.+)", "favorite_is"),
        ]

        for pattern, predicate in preference_patterns:
            match = re.search(pattern, text)
            if match:
                memory = create_memory_chunk(
                    user_id=user_id,
                    subject=user_id,
                    predicate=predicate,
                    obj=match.group(1),
                    memory_type=MemoryType.PREFERENCE,
                    chat_id=context.get("chat_id"),
                    importance=ImportanceLevel.NORMAL,
                    confidence=ConfidenceLevel.MEDIUM
                )

                memories.append(memory)

        return memories

    def _extract_events(
        self,
        text: str,
        user_id: str,
        timestamp: float,
        context: Dict[str, Any]
    ) -> List[MemoryChunk]:
        """æå–äº‹ä»¶ä¿¡æ¯"""
        memories = []

        # äº‹ä»¶å…³é”®è¯
        event_keywords = ["æ˜å¤©", "ä»Šå¤©", "æ˜¨å¤©", "ä¸Šå‘¨", "ä¸‹å‘¨", "çº¦ä¼š", "ä¼šè®®", "æ´»åŠ¨", "æ—…è¡Œ", "ç”Ÿæ—¥"]

        if any(keyword in text for keyword in event_keywords):
            memory = create_memory_chunk(
                user_id=user_id,
                subject=user_id,
                predicate="mentioned_event",
                obj={"event_text": text, "timestamp": timestamp},
                memory_type=MemoryType.EVENT,
                chat_id=context.get("chat_id"),
                importance=ImportanceLevel.NORMAL,
                confidence=ConfidenceLevel.MEDIUM
            )

            memories.append(memory)

        return memories

    def _merge_hybrid_results(
        self,
        rule_memories: List[MemoryChunk],
        llm_memories: List[MemoryChunk]
    ) -> List[MemoryChunk]:
        """åˆå¹¶æ··åˆç­–ç•¥ç»“æœ"""
        all_memories = rule_memories.copy()

        # æ·»åŠ LLMè®°å¿†ï¼Œé¿å…é‡å¤
        for llm_memory in llm_memories:
            is_duplicate = False
            for rule_memory in rule_memories:
                if llm_memory.is_similar_to(rule_memory, threshold=0.7):
                    is_duplicate = True
                    # åˆå¹¶ç½®ä¿¡åº¦
                    rule_memory.metadata.confidence = ConfidenceLevel(
                        max(rule_memory.metadata.confidence.value, llm_memory.metadata.confidence.value)
                    )
                    break

            if not is_duplicate:
                all_memories.append(llm_memory)

        return all_memories

    def _validate_and_enhance_memories(
        self,
        memories: List[MemoryChunk],
        context: Dict[str, Any]
    ) -> List[MemoryChunk]:
        """éªŒè¯å’Œå¢å¼ºè®°å¿†"""
        validated_memories = []

        for memory in memories:
            # åŸºæœ¬éªŒè¯
            if not self._validate_memory(memory):
                continue

            # å¢å¼ºè®°å¿†
            enhanced_memory = self._enhance_memory(memory, context)
            validated_memories.append(enhanced_memory)

        return validated_memories

    def _validate_memory(self, memory: MemoryChunk) -> bool:
        """éªŒè¯è®°å¿†å—"""
        # æ£€æŸ¥åŸºæœ¬å­—æ®µ
        if not memory.content.subject or not memory.content.predicate:
            logger.debug(f"è®°å¿†å—ç¼ºå°‘ä¸»è¯­æˆ–è°“è¯­: {memory.memory_id}")
            return False

        # æ£€æŸ¥å†…å®¹é•¿åº¦
        content_length = len(memory.text_content)
        if content_length < 5 or content_length > 500:
            logger.debug(f"è®°å¿†å—å†…å®¹é•¿åº¦å¼‚å¸¸: {content_length}")
            return False

        # æ£€æŸ¥ç½®ä¿¡åº¦
        if memory.metadata.confidence == ConfidenceLevel.LOW:
            logger.debug(f"è®°å¿†å—ç½®ä¿¡åº¦è¿‡ä½: {memory.memory_id}")
            return False

        return True

    def _enhance_memory(
        self,
        memory: MemoryChunk,
        context: Dict[str, Any]
    ) -> MemoryChunk:
        """å¢å¼ºè®°å¿†å—"""
        # æ—¶é—´è§„èŒƒåŒ–å¤„ç†
        self._normalize_time_in_memory(memory)

        # æ·»åŠ æ—¶é—´ä¸Šä¸‹æ–‡
        if not memory.temporal_context:
            memory.temporal_context = {
                "timestamp": memory.metadata.created_at,
                "timezone": context.get("timezone", "UTC"),
                "day_of_week": datetime.fromtimestamp(memory.metadata.created_at).strftime("%A")
            }

        # æ·»åŠ æƒ…æ„Ÿä¸Šä¸‹æ–‡ï¼ˆå¦‚æœæœ‰ï¼‰
        if context.get("sentiment"):
            memory.metadata.emotional_context = context["sentiment"]

        # è‡ªåŠ¨æ·»åŠ æ ‡ç­¾
        self._auto_tag_memory(memory)

        return memory

    def _normalize_time_in_memory(self, memory: MemoryChunk):
        """è§„èŒƒåŒ–è®°å¿†ä¸­çš„æ—¶é—´è¡¨è¾¾"""
        import re
        from datetime import datetime, timedelta

        # è·å–å½“å‰æ—¶é—´ä½œä¸ºå‚è€ƒ
        current_time = datetime.fromtimestamp(memory.metadata.created_at)

        # å®šä¹‰ç›¸å¯¹æ—¶é—´æ˜ å°„
        relative_time_patterns = {
            r'ä»Šå¤©|ä»Šæ—¥': current_time.strftime('%Y-%m-%d'),
            r'æ˜¨å¤©|æ˜¨æ—¥': (current_time - timedelta(days=1)).strftime('%Y-%m-%d'),
            r'æ˜å¤©|æ˜æ—¥': (current_time + timedelta(days=1)).strftime('%Y-%m-%d'),
            r'åå¤©': (current_time + timedelta(days=2)).strftime('%Y-%m-%d'),
            r'å¤§åå¤©': (current_time + timedelta(days=3)).strftime('%Y-%m-%d'),
            r'å‰å¤©': (current_time - timedelta(days=2)).strftime('%Y-%m-%d'),
            r'å¤§å‰å¤©': (current_time - timedelta(days=3)).strftime('%Y-%m-%d'),
            r'æœ¬å‘¨|è¿™å‘¨|è¿™æ˜ŸæœŸ': current_time.strftime('%Y-%m-%d'),
            r'ä¸Šå‘¨|ä¸Šæ˜ŸæœŸ': (current_time - timedelta(weeks=1)).strftime('%Y-%m-%d'),
            r'ä¸‹å‘¨|ä¸‹æ˜ŸæœŸ': (current_time + timedelta(weeks=1)).strftime('%Y-%m-%d'),
            r'æœ¬æœˆ|è¿™ä¸ªæœˆ': current_time.strftime('%Y-%m-01'),
            r'ä¸Šæœˆ|ä¸Šä¸ªæœˆ': (current_time.replace(day=1) - timedelta(days=1)).strftime('%Y-%m-01'),
            r'ä¸‹æœˆ|ä¸‹ä¸ªæœˆ': (current_time.replace(day=1) + timedelta(days=32)).replace(day=1).strftime('%Y-%m-01'),
            r'ä»Šå¹´|ä»Šå¹´': current_time.strftime('%Y'),
            r'å»å¹´|ä¸Šä¸€å¹´': str(current_time.year - 1),
            r'æ˜å¹´|ä¸‹ä¸€å¹´': str(current_time.year + 1),
        }

        # æ£€æŸ¥å¹¶æ›¿æ¢è®°å¿†å†…å®¹ä¸­çš„ç›¸å¯¹æ—¶é—´
        memory_content = memory.content.description

        # åº”ç”¨æ—¶é—´è§„èŒƒåŒ–
        for pattern, replacement in relative_time_patterns.items():
            memory_content = re.sub(pattern, replacement, memory_content)

        # æ›´æ–°è®°å¿†å†…å®¹
        memory.content.description = memory_content

        # å¦‚æœè®°å¿†æœ‰å¯¹è±¡ä¿¡æ¯ï¼Œä¹Ÿè¿›è¡Œæ—¶é—´è§„èŒƒåŒ–
        if hasattr(memory.content, 'object') and isinstance(memory.content.object, dict):
            obj_str = str(memory.content.object)
            for pattern, replacement in relative_time_patterns.items():
                obj_str = re.sub(pattern, replacement, obj_str)
            try:
                # å°è¯•è§£æå›å­—å…¸ï¼ˆå¦‚æœåŸæ¥æ˜¯å­—å…¸ï¼‰
                memory.content.object = eval(obj_str) if obj_str.startswith('{') else obj_str
            except:
                memory.content.object = obj_str

        # è®°å½•æ—¶é—´è§„èŒƒåŒ–æ“ä½œ
        logger.debug(f"è®°å¿† {memory.memory_id} å·²è¿›è¡Œæ—¶é—´è§„èŒƒåŒ–")

    def _auto_tag_memory(self, memory: MemoryChunk):
        """è‡ªåŠ¨ä¸ºè®°å¿†æ·»åŠ æ ‡ç­¾"""
        # åŸºäºè®°å¿†ç±»å‹çš„è‡ªåŠ¨æ ‡ç­¾
        type_tags = {
            MemoryType.PERSONAL_FACT: ["ä¸ªäººä¿¡æ¯", "åŸºæœ¬èµ„æ–™"],
            MemoryType.EVENT: ["äº‹ä»¶", "æ—¥ç¨‹"],
            MemoryType.PREFERENCE: ["åå¥½", "å–œå¥½"],
            MemoryType.OPINION: ["è§‚ç‚¹", "æ€åº¦"],
            MemoryType.RELATIONSHIP: ["å…³ç³»", "ç¤¾äº¤"],
            MemoryType.EMOTION: ["æƒ…æ„Ÿ", "æƒ…ç»ª"],
            MemoryType.KNOWLEDGE: ["çŸ¥è¯†", "ä¿¡æ¯"],
            MemoryType.SKILL: ["æŠ€èƒ½", "èƒ½åŠ›"],
            MemoryType.GOAL: ["ç›®æ ‡", "è®¡åˆ’"],
            MemoryType.EXPERIENCE: ["ç»éªŒ", "ç»å†"],
        }

        tags = type_tags.get(memory.memory_type, [])
        for tag in tags:
            memory.add_tag(tag)

    def _update_extraction_stats(self, success_count: int, extraction_time: float):
        """æ›´æ–°æå–ç»Ÿè®¡"""
        self.extraction_stats["total_extractions"] += 1
        self.extraction_stats["successful_extractions"] += success_count
        self.extraction_stats["failed_extractions"] += max(0, 1 - success_count)

        # æ›´æ–°å¹³å‡ç½®ä¿¡åº¦
        if self.extraction_stats["successful_extractions"] > 0:
            total_confidence = self.extraction_stats["average_confidence"] * (self.extraction_stats["successful_extractions"] - success_count)
            # å‡è®¾æ–°è®°å¿†çš„å¹³å‡ç½®ä¿¡åº¦ä¸º0.8
            total_confidence += 0.8 * success_count
            self.extraction_stats["average_confidence"] = total_confidence / self.extraction_stats["successful_extractions"]

    def get_extraction_stats(self) -> Dict[str, Any]:
        """è·å–æå–ç»Ÿè®¡ä¿¡æ¯"""
        return self.extraction_stats.copy()

    def reset_stats(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self.extraction_stats = {
            "total_extractions": 0,
            "successful_extractions": 0,
            "failed_extractions": 0,
            "average_confidence": 0.0
        }