"""
QQç©ºé—´æœåŠ¡æ¨¡å—
å°è£…äº†æ‰€æœ‰ä¸QQç©ºé—´APIçš„ç›´æ¥äº¤äº’ï¼Œæ˜¯æ’ä»¶çš„æ ¸å¿ƒä¸šåŠ¡é€»è¾‘å±‚ã€‚
"""

import asyncio
import base64
import random
import time
from collections.abc import Callable
from pathlib import Path
from typing import Any

import aiofiles
import aiohttp
import bs4
import json5
import orjson

from src.common.logger import get_logger
from src.plugin_system.apis import config_api, cross_context_api, person_api

from .content_service import ContentService
from .cookie_service import CookieService
from .image_service import ImageService
from .reply_tracker_service import ReplyTrackerService

logger = get_logger("MaiZone.QZoneService")


class QZoneService:
    """
    QQç©ºé—´æœåŠ¡ç±»ï¼Œè´Ÿè´£æ‰€æœ‰APIäº¤äº’å’Œä¸šåŠ¡æµç¨‹ç¼–æ’ã€‚
    """

    # --- API Endpoints ---
    ZONE_LIST_URL = "https://user.qzone.qq.com/proxy/domain/ic2.qzone.qq.com/cgi-bin/feeds/feeds3_html_more"
    EMOTION_PUBLISH_URL = "https://user.qzone.qq.com/proxy/domain/taotao.qzone.qq.com/cgi-bin/emotion_cgi_publish_v6"
    DOLIKE_URL = "https://user.qzone.qq.com/proxy/domain/w.qzone.qq.com/cgi-bin/likes/internal_dolike_app"
    COMMENT_URL = "https://user.qzone.qq.com/proxy/domain/taotao.qzone.qq.com/cgi-bin/emotion_cgi_re_feeds"
    LIST_URL = "https://user.qzone.qq.com/proxy/domain/taotao.qq.com/cgi-bin/emotion_cgi_msglist_v6"
    REPLY_URL = "https://user.qzone.qq.com/proxy/domain/taotao.qzone.qq.com/cgi-bin/emotion_cgi_re_feeds"

    def __init__(
        self,
        get_config: Callable,
        content_service: ContentService,
        image_service: ImageService,
        cookie_service: CookieService,
        reply_tracker: ReplyTrackerService | None = None,
    ):
        self.get_config = get_config
        self.content_service = content_service
        self.image_service = image_service
        self.cookie_service = cookie_service
        # å¦‚æœæ²¡æœ‰æä¾› reply_tracker å®ä¾‹ï¼Œåˆ™åˆ›å»ºä¸€ä¸ªæ–°çš„
        self.reply_tracker = reply_tracker if reply_tracker is not None else ReplyTrackerService()
        # ç”¨äºé˜²æ­¢å¹¶å‘å›å¤/è¯„è®ºçš„å†…å­˜é”
        self.processing_comments = set()

    # --- Public Methods (High-Level Business Logic) ---
    async def _get_cross_context(self) -> str:
        """è·å–å¹¶æ„å»ºè·¨ç¾¤èŠä¸Šä¸‹æ–‡"""
        context = ""
        user_id = self.get_config("cross_context.user_id")

        if user_id:
            logger.info(f"æ£€æµ‹åˆ°äº’é€šç»„ç”¨æˆ·ID: {user_id}ï¼Œå‡†å¤‡è·å–ä¸Šä¸‹æ–‡...")
            try:
                context = await cross_context_api.build_cross_context_for_user(
                    user_id=user_id,
                    platform="QQ",  # ç¡¬ç¼–ç ä¸ºQQ
                    limit_per_stream=10,
                    stream_limit=3,
                )
                if context:
                    logger.info("æˆåŠŸè·å–åˆ°äº’é€šç»„ä¸Šä¸‹æ–‡ã€‚")
                else:
                    logger.info("æœªè·å–åˆ°æœ‰æ•ˆçš„äº’é€šç»„ä¸Šä¸‹æ–‡ã€‚")
            except Exception as e:
                logger.error(f"è·å–äº’é€šç»„ä¸Šä¸‹æ–‡æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
        return context

    async def send_feed(self, topic: str, stream_id: str | None) -> dict[str, Any]:
        """å‘é€ä¸€æ¡è¯´è¯´ï¼ˆæ”¯æŒAIé…å›¾ï¼‰"""
        cross_context = await self._get_cross_context()

        # æ£€æŸ¥æ˜¯å¦å¯ç”¨AIé…å›¾
        ai_image_enabled = self.get_config("ai_image.enable_ai_image", False)
        provider = self.get_config("ai_image.provider", "siliconflow")

        image_path = None

        if ai_image_enabled:
            # å¯ç”¨AIé…å›¾ï¼šæ–‡æœ¬æ¨¡å‹ç”Ÿæˆè¯´è¯´+å›¾ç‰‡æç¤ºè¯
            story, image_info = await self.content_service.generate_story_with_image_info(topic, context=cross_context)
            if not story:
                return {"success": False, "message": "ç”Ÿæˆè¯´è¯´å†…å®¹å¤±è´¥"}

            # æ ¹æ®providerè°ƒç”¨å¯¹åº”çš„ç”Ÿå›¾æœåŠ¡
            if provider == "novelai":
                try:
                    from .novelai_service import MaiZoneNovelAIService
                    novelai_service = MaiZoneNovelAIService(self.get_config)

                    if novelai_service.is_available():
                        # è§£æç”»å¹…
                        aspect_ratio = image_info.get("aspect_ratio", "æ–¹å›¾")
                        size_map = {
                            "æ–¹å›¾": (1024, 1024),
                            "æ¨ªå›¾": (1216, 832),
                            "ç«–å›¾": (832, 1216),
                        }
                        width, height = size_map.get(aspect_ratio, (1024, 1024))

                        logger.info("ğŸ¨ å¼€å§‹ç”ŸæˆNovelAIé…å›¾...")
                        success, img_path, msg = await novelai_service.generate_image_from_prompt_data(
                            prompt=image_info.get("prompt", ""),
                            negative_prompt=image_info.get("negative_prompt"),
                            include_character=image_info.get("include_character", False),
                            width=width,
                            height=height
                        )

                        if success and img_path:
                            image_path = img_path
                            logger.info("âœ… NovelAIé…å›¾ç”ŸæˆæˆåŠŸ")
                        else:
                            logger.warning(f"âš ï¸ NovelAIé…å›¾ç”Ÿæˆå¤±è´¥: {msg}")
                    else:
                        logger.warning("NovelAIæœåŠ¡ä¸å¯ç”¨ï¼ˆæœªé…ç½®API Keyï¼‰")

                except Exception as e:
                    logger.error(f"NovelAIé…å›¾ç”Ÿæˆå‡ºé”™: {e}", exc_info=True)

            elif provider == "siliconflow":
                try:
                    # è°ƒç”¨ç¡…åŸºæµåŠ¨ç”Ÿæˆå›¾ç‰‡
                    success, img_path = await self.image_service.generate_image_from_prompt(
                        prompt=image_info.get("prompt", ""),
                        save_dir=None  # ä½¿ç”¨é»˜è®¤imagesç›®å½•
                    )
                    if success and img_path:
                        image_path = img_path
                        logger.info("âœ… ç¡…åŸºæµåŠ¨é…å›¾ç”ŸæˆæˆåŠŸ")
                    else:
                        logger.warning("âš ï¸ ç¡…åŸºæµåŠ¨é…å›¾ç”Ÿæˆå¤±è´¥")
                except Exception as e:
                    logger.error(f"ç¡…åŸºæµåŠ¨é…å›¾ç”Ÿæˆå‡ºé”™: {e}", exc_info=True)
        else:
            # ä¸ä½¿ç”¨AIé…å›¾ï¼šåªç”Ÿæˆè¯´è¯´æ–‡æœ¬
            story = await self.content_service.generate_story(topic, context=cross_context)
            if not story:
                return {"success": False, "message": "ç”Ÿæˆè¯´è¯´å†…å®¹å¤±è´¥"}

        qq_account = config_api.get_global_config("bot.qq_account", "")
        api_client = await self._get_api_client(qq_account, stream_id)
        if not api_client:
            return {"success": False, "message": "è·å–QZone APIå®¢æˆ·ç«¯å¤±è´¥"}

        # åŠ è½½å›¾ç‰‡
        images_bytes = []

        # ä½¿ç”¨AIç”Ÿæˆçš„å›¾ç‰‡
        if image_path and image_path.exists():
            try:
                with open(image_path, "rb") as f:
                    images_bytes.append(f.read())
                logger.info("æ·»åŠ AIé…å›¾åˆ°è¯´è¯´")
            except Exception as e:
                logger.error(f"è¯»å–AIé…å›¾å¤±è´¥: {e}")

        try:
            success, _ = await api_client["publish"](story, images_bytes)
            if success:
                return {"success": True, "message": story}
            return {"success": False, "message": "å‘å¸ƒè¯´è¯´è‡³QQç©ºé—´å¤±è´¥"}
        except Exception as e:
            logger.error(f"å‘å¸ƒè¯´è¯´æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            return {"success": False, "message": f"å‘å¸ƒè¯´è¯´å¼‚å¸¸: {e}"}

    async def send_feed_from_activity(self, activity: str) -> dict[str, Any]:
        """æ ¹æ®æ—¥ç¨‹æ´»åŠ¨å‘é€ä¸€æ¡è¯´è¯´"""
        cross_context = await self._get_cross_context()
        story = await self.content_service.generate_story_from_activity(activity, context=cross_context)
        if not story:
            return {"success": False, "message": "æ ¹æ®æ´»åŠ¨ç”Ÿæˆè¯´è¯´å†…å®¹å¤±è´¥"}

        if self.get_config("send.enable_ai_image", False):
            await self.image_service.generate_images_for_story(story)

        qq_account = config_api.get_global_config("bot.qq_account", "")
        api_client = await self._get_api_client(qq_account, stream_id=None)
        if not api_client:
            return {"success": False, "message": "è·å–QZone APIå®¢æˆ·ç«¯å¤±è´¥"}

        try:
            success, _ = await api_client["publish"](story, [])
            if success:
                return {"success": True, "message": story}
            return {"success": False, "message": "å‘å¸ƒè¯´è¯´è‡³QQç©ºé—´å¤±è´¥"}
        except Exception as e:
            logger.error(f"æ ¹æ®æ´»åŠ¨å‘å¸ƒè¯´è¯´æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            return {"success": False, "message": f"å‘å¸ƒè¯´è¯´å¼‚å¸¸: {e}"}

    async def read_and_process_feeds(self, target_name: str, stream_id: str | None) -> dict[str, Any]:
        """è¯»å–å¹¶å¤„ç†æŒ‡å®šå¥½å‹çš„è¯´è¯´"""
        # åˆ¤æ–­è¾“å…¥æ˜¯QQå·è¿˜æ˜¯æ˜µç§°
        target_qq = None

        if target_name.isdigit():
            # è¾“å…¥æ˜¯çº¯æ•°å­—ï¼Œå½“ä½œQQå·å¤„ç†
            target_qq = int(target_name)
        else:
            # è¾“å…¥æ˜¯æ˜µç§°ï¼ŒæŸ¥è¯¢person_infoè·å–QQå·
            target_person_id = await person_api.get_person_id_by_name(target_name)
            if not target_person_id:
                return {"success": False, "message": f"æ‰¾ä¸åˆ°åä¸º'{target_name}'çš„å¥½å‹"}
            person_info = await person_api.get_person_info(target_person_id)
            target_qq = person_info.get("user_id")
            if not target_qq:
                return {"success": False, "message": f"å¥½å‹'{target_name}'æ²¡æœ‰å…³è”QQå·"}

        qq_account = config_api.get_global_config("bot.qq_account", "")
        logger.debug(f"å‡†å¤‡è·å–APIå®¢æˆ·ç«¯ï¼Œqq_account={qq_account}")
        api_client = await self._get_api_client(qq_account, stream_id)
        if not api_client:
            logger.error("APIå®¢æˆ·ç«¯è·å–å¤±è´¥ï¼Œè¿”å›é”™è¯¯")
            return {"success": False, "message": "è·å–QZone APIå®¢æˆ·ç«¯å¤±è´¥"}

        logger.debug("APIå®¢æˆ·ç«¯è·å–æˆåŠŸï¼Œå‡†å¤‡è¯»å–è¯´è¯´")
        num_to_read = self.get_config("read.read_number", 5)

        # å°è¯•æ‰§è¡Œï¼Œå¦‚æœCookieå¤±æ•ˆåˆ™è‡ªåŠ¨é‡è¯•ä¸€æ¬¡
        for retry_count in range(2):  # æœ€å¤šå°è¯•2æ¬¡
            try:
                logger.debug(f"å¼€å§‹è°ƒç”¨ list_feedsï¼Œtarget_qq={target_qq}, num={num_to_read}")
                feeds = await api_client["list_feeds"](target_qq, num_to_read)
                logger.debug(f"list_feeds è¿”å›ï¼Œfeedsæ•°é‡={len(feeds) if feeds else 0}")
                if not feeds:
                    return {"success": True, "message": f"æ²¡æœ‰ä»'{target_name}'çš„ç©ºé—´è·å–åˆ°æ–°è¯´è¯´ã€‚"}

                logger.debug(f"å‡†å¤‡å¤„ç† {len(feeds)} æ¡è¯´è¯´")
                total_liked = 0
                total_commented = 0
                for feed in feeds:
                    result = await self._process_single_feed(feed, api_client, str(target_qq), target_name)
                    if result["liked"]:
                        total_liked += 1
                    if result["commented"]:
                        total_commented += 1
                    await asyncio.sleep(random.uniform(3, 7))

                # æ„å»ºè¯¦ç»†çš„åé¦ˆä¿¡æ¯
                stats_parts = []
                if total_liked > 0:
                    stats_parts.append(f"ç‚¹èµäº†{total_liked}æ¡")
                if total_commented > 0:
                    stats_parts.append(f"è¯„è®ºäº†{total_commented}æ¡")

                if stats_parts:
                    stats_msg = "ã€".join(stats_parts)
                    message = f"æˆåŠŸæŸ¥çœ‹äº†'{target_name}'çš„ç©ºé—´ï¼Œ{stats_msg}ã€‚"
                else:
                    message = f"æˆåŠŸæŸ¥çœ‹äº†'{target_name}'çš„ {len(feeds)} æ¡è¯´è¯´ï¼Œä½†è¿™æ¬¡æ²¡æœ‰è¿›è¡Œäº’åŠ¨ã€‚"

                return {
                    "success": True,
                    "message": message,
                    "stats": {"total": len(feeds), "liked": total_liked, "commented": total_commented},
                }
            except RuntimeError as e:
                # QQç©ºé—´APIè¿”å›çš„ä¸šåŠ¡é”™è¯¯
                error_msg = str(e)

                # æ£€æŸ¥æ˜¯å¦æ˜¯Cookieå¤±æ•ˆï¼ˆ-3000é”™è¯¯ï¼‰
                if "é”™è¯¯ç : -3000" in error_msg and retry_count == 0:
                    logger.warning("æ£€æµ‹åˆ°Cookieå¤±æ•ˆï¼ˆ-3000é”™è¯¯ï¼‰ï¼Œå‡†å¤‡åˆ é™¤ç¼“å­˜å¹¶é‡è¯•...")

                    # åˆ é™¤Cookieç¼“å­˜æ–‡ä»¶
                    cookie_file = self.cookie_service._get_cookie_file_path(qq_account)
                    if cookie_file.exists():
                        try:
                            cookie_file.unlink()
                            logger.info(f"å·²åˆ é™¤è¿‡æœŸçš„Cookieç¼“å­˜æ–‡ä»¶: {cookie_file}")
                        except Exception as delete_error:
                            logger.error(f"åˆ é™¤Cookieæ–‡ä»¶å¤±è´¥: {delete_error}")

                    # é‡æ–°è·å–APIå®¢æˆ·ç«¯ï¼ˆä¼šè‡ªåŠ¨è·å–æ–°Cookieï¼‰
                    logger.info("æ­£åœ¨é‡æ–°è·å–Cookie...")
                    api_client = await self._get_api_client(qq_account, stream_id)
                    if not api_client:
                        logger.error("é‡æ–°è·å–APIå®¢æˆ·ç«¯å¤±è´¥")
                        return {"success": False, "message": "Cookieå·²å¤±æ•ˆï¼Œä¸”æ— æ³•é‡æ–°è·å–ã€‚è¯·æ£€æŸ¥Botå’ŒNapcatè¿æ¥çŠ¶æ€ã€‚"}

                    logger.info("Cookieå·²æ›´æ–°ï¼Œæ­£åœ¨é‡è¯•...")
                    continue  # ç»§ç»­å¾ªç¯ï¼Œé‡è¯•ä¸€æ¬¡

                # å…¶ä»–ä¸šåŠ¡é”™è¯¯æˆ–é‡è¯•åä»å¤±è´¥
                logger.warning(f"QQç©ºé—´APIé”™è¯¯: {e}")
                return {"success": False, "message": error_msg}
            except Exception as e:
                # å…¶ä»–æœªçŸ¥å¼‚å¸¸
                logger.error(f"è¯»å–å’Œå¤„ç†è¯´è¯´æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
                return {"success": False, "message": f"å¤„ç†è¯´è¯´æ—¶å‡ºç°å¼‚å¸¸: {e}"}
        return {"success": False, "message": "è¯»å–å’Œå¤„ç†è¯´è¯´æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼Œå¾ªç¯æ„å¤–ç»“æŸã€‚"}

    async def monitor_feeds(self, stream_id: str | None = None):
        """ç›‘æ§å¹¶å¤„ç†æ‰€æœ‰å¥½å‹çš„åŠ¨æ€ï¼ŒåŒ…æ‹¬å›å¤è‡ªå·±è¯´è¯´çš„è¯„è®º"""
        logger.info("å¼€å§‹æ‰§è¡Œå¥½å‹åŠ¨æ€ç›‘æ§...")
        qq_account = config_api.get_global_config("bot.qq_account", "")

        # å°è¯•æ‰§è¡Œï¼Œå¦‚æœCookieå¤±æ•ˆåˆ™è‡ªåŠ¨é‡è¯•ä¸€æ¬¡
        for retry_count in range(2):  # æœ€å¤šå°è¯•2æ¬¡
            api_client = await self._get_api_client(qq_account, stream_id)
            if not api_client:
                logger.error("ç›‘æ§å¤±è´¥ï¼šæ— æ³•è·å–APIå®¢æˆ·ç«¯")
                return

            try:
                # --- ç¬¬ä¸€æ­¥: å•ç‹¬å¤„ç†è‡ªå·±è¯´è¯´çš„è¯„è®º ---
                if self.get_config("monitor.enable_auto_reply", False):
                    try:
                        # ä¼ å…¥æ–°å‚æ•°ï¼Œè¡¨æ˜æ­£åœ¨æ£€æŸ¥è‡ªå·±çš„è¯´è¯´
                        own_feeds = await api_client["list_feeds"](qq_account, 5)
                        if own_feeds:
                            logger.info(f"è·å–åˆ°è‡ªå·± {len(own_feeds)} æ¡è¯´è¯´ï¼Œæ£€æŸ¥è¯„è®º...")
                            for feed in own_feeds:
                                await self._reply_to_own_feed_comments(feed, api_client)
                                await asyncio.sleep(random.uniform(3, 5))
                    except Exception as e:
                        logger.error(f"å¤„ç†è‡ªå·±è¯´è¯´è¯„è®ºæ—¶å‘ç”Ÿå¼‚å¸¸: {e}")

                # --- ç¬¬äºŒæ­¥: å¤„ç†å¥½å‹çš„åŠ¨æ€ ---
                friend_feeds = await api_client["monitor_list_feeds"](20)
                if not friend_feeds:
                    logger.info("ç›‘æ§å®Œæˆï¼šæœªå‘ç°å¥½å‹æ–°è¯´è¯´")
                    return

                logger.info(f"ç›‘æ§ä»»åŠ¡: å‘ç° {len(friend_feeds)} æ¡å¥½å‹æ–°åŠ¨æ€ï¼Œå‡†å¤‡å¤„ç†...")
                monitor_stats = {"total": 0, "liked": 0, "commented": 0}
                for feed in friend_feeds:
                    target_qq = feed.get("target_qq")
                    if not target_qq or str(target_qq) == str(qq_account):  # ç¡®ä¿ä¸é‡å¤å¤„ç†è‡ªå·±çš„
                        continue

                    result = await self._process_single_feed(feed, api_client, str(target_qq), str(target_qq))
                    monitor_stats["total"] += 1
                    if result.get("liked"):
                        monitor_stats["liked"] += 1
                    if result.get("commented"):
                        monitor_stats["commented"] += 1
                    await asyncio.sleep(random.uniform(5, 10))

                logger.info(
                    f"ç›‘æ§ä»»åŠ¡å®Œæˆ: å¤„ç†äº†{monitor_stats['total']}æ¡åŠ¨æ€ï¼Œ"
                    f"ç‚¹èµ{monitor_stats['liked']}æ¡ï¼Œè¯„è®º{monitor_stats['commented']}æ¡"
                )
                return  # æˆåŠŸå®Œæˆï¼Œç›´æ¥è¿”å›

            except RuntimeError as e:
                # QQç©ºé—´APIè¿”å›çš„ä¸šåŠ¡é”™è¯¯
                error_msg = str(e)

                # æ£€æŸ¥æ˜¯å¦æ˜¯Cookieå¤±æ•ˆï¼ˆ-3000é”™è¯¯ï¼‰
                if "é”™è¯¯ç : -3000" in error_msg and retry_count == 0:
                    logger.warning("æ£€æµ‹åˆ°Cookieå¤±æ•ˆï¼ˆ-3000é”™è¯¯ï¼‰ï¼Œå‡†å¤‡åˆ é™¤ç¼“å­˜å¹¶é‡è¯•...")

                    # åˆ é™¤Cookieç¼“å­˜æ–‡ä»¶
                    cookie_file = self.cookie_service._get_cookie_file_path(qq_account)
                    if cookie_file.exists():
                        try:
                            cookie_file.unlink()
                            logger.info(f"å·²åˆ é™¤è¿‡æœŸçš„Cookieç¼“å­˜æ–‡ä»¶: {cookie_file}")
                        except Exception as delete_error:
                            logger.error(f"åˆ é™¤Cookieæ–‡ä»¶å¤±è´¥: {delete_error}")

                    # é‡æ–°è·å–APIå®¢æˆ·ç«¯ä¼šåœ¨ä¸‹ä¸€æ¬¡å¾ªç¯ä¸­è‡ªåŠ¨è¿›è¡Œ
                    logger.info("Cookieå·²åˆ é™¤ï¼Œæ­£åœ¨é‡è¯•...")
                    continue  # ç»§ç»­å¾ªç¯ï¼Œé‡è¯•ä¸€æ¬¡

                # å…¶ä»–ä¸šåŠ¡é”™è¯¯æˆ–é‡è¯•åä»å¤±è´¥
                logger.error(f"ç›‘æ§å¥½å‹åŠ¨æ€æ—¶å‘ç”Ÿä¸šåŠ¡é”™è¯¯: {e}")
                return

            except Exception as e:
                # å…¶ä»–æœªçŸ¥å¼‚å¸¸
                logger.error(f"ç›‘æ§å¥½å‹åŠ¨æ€æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
                return

    # --- Internal Helper Methods ---


    async def _reply_to_own_feed_comments(self, feed: dict, api_client: dict):
        """å¤„ç†å¯¹è‡ªå·±è¯´è¯´çš„è¯„è®ºå¹¶è¿›è¡Œå›å¤"""
        qq_account = config_api.get_global_config("bot.qq_account", "")
        comments = feed.get("comments", [])
        content = feed.get("content", "")
        fid = feed.get("tid", "")

        if not comments or not fid:
            return

        # 1. å°†è¯„è®ºåˆ†ä¸ºç”¨æˆ·è¯„è®ºå’Œè‡ªå·±çš„å›å¤
        user_comments = [c for c in comments if str(c.get("qq_account")) != str(qq_account)]

        if not user_comments:
            return

        # ç›´æ¥æ£€æŸ¥è¯„è®ºæ˜¯å¦å·²å›å¤ï¼Œä¸åšéªŒè¯æ¸…ç†
        comments_to_process = []
        for comment in user_comments:
            comment_tid = comment.get("comment_tid")
            if not comment_tid:
                continue

            comment_key = f"{fid}_{comment_tid}"
            # æ£€æŸ¥æŒä¹…åŒ–è®°å½•å’Œå†…å­˜é”
            if not self.reply_tracker.has_replied(fid, comment_tid) and comment_key not in self.processing_comments:
                logger.debug(f"é”å®šå¾…å›å¤è¯„è®º: {comment_key}")
                self.processing_comments.add(comment_key)
                comments_to_process.append(comment)

        if not comments_to_process:
            logger.debug(f"è¯´è¯´ {fid} ä¸‹çš„æ‰€æœ‰è¯„è®ºéƒ½å·²å›å¤è¿‡æˆ–æ­£åœ¨å¤„ç†ä¸­")
            return

        logger.info(f"å‘ç°è‡ªå·±è¯´è¯´ä¸‹çš„ {len(comments_to_process)} æ¡æ–°è¯„è®ºï¼Œå‡†å¤‡å›å¤...")
        for comment in comments_to_process:
            comment_tid = comment.get("comment_tid")
            comment_key = f"{fid}_{comment_tid}"
            nickname = comment.get("nickname", "")
            comment_content = comment.get("content", "")
            commenter_qq = str(comment.get("qq_account", "")) if comment.get("qq_account") else None

            try:
                reply_content = await self.content_service.generate_comment_reply(
                    story_content=content,
                    comment_content=comment_content,
                    commenter_name=nickname,
                    commenter_qq=commenter_qq,
                )
                if reply_content:
                    success = await api_client["reply"](fid, qq_account, nickname, reply_content, comment_tid)
                    if success:
                        self.reply_tracker.mark_as_replied(fid, comment_tid)
                        logger.info(f"æˆåŠŸå›å¤'{nickname}'çš„è¯„è®º: '{reply_content}'")
                    else:
                        logger.error(f"å›å¤'{nickname}'çš„è¯„è®ºå¤±è´¥")
                    await asyncio.sleep(random.uniform(10, 20))
                else:
                    logger.warning(f"ç”Ÿæˆå›å¤å†…å®¹å¤±è´¥ï¼Œè·³è¿‡å›å¤'{nickname}'çš„è¯„è®º")
            except Exception as e:
                logger.error(f"å›å¤'{nickname}'çš„è¯„è®ºæ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            finally:
                # æ— è®ºæˆåŠŸä¸å¦ï¼Œéƒ½è§£é™¤é”å®š
                logger.debug(f"è§£é”è¯„è®º: {comment_key}")
                if comment_key in self.processing_comments:
                    self.processing_comments.remove(comment_key)

    async def _validate_and_cleanup_reply_records(self, fid: str, my_replies: list[dict]):
        """éªŒè¯å¹¶æ¸…ç†å·²åˆ é™¤çš„å›å¤è®°å½•"""
        # è·å–å½“å‰è®°å½•ä¸­è¯¥è¯´è¯´çš„æ‰€æœ‰å·²å›å¤è¯„è®ºID
        recorded_replied_comments = self.reply_tracker.get_replied_comments(fid)

        if not recorded_replied_comments:
            return

        # ä»APIè¿”å›çš„æˆ‘çš„å›å¤ä¸­æå–parent_tidï¼ˆå³è¢«å›å¤çš„è¯„è®ºIDï¼‰
        current_replied_comments = set()
        for reply in my_replies:
            parent_tid = reply.get("parent_tid")
            if parent_tid:
                current_replied_comments.add(parent_tid)

        # æ‰¾å‡ºè®°å½•ä¸­æœ‰ä½†å®é™…å·²ä¸å­˜åœ¨çš„å›å¤
        deleted_replies = recorded_replied_comments - current_replied_comments

        if deleted_replies:
            logger.info(f"æ£€æµ‹åˆ° {len(deleted_replies)} ä¸ªå›å¤å·²è¢«åˆ é™¤ï¼Œæ¸…ç†è®°å½•...")
            for comment_tid in deleted_replies:
                self.reply_tracker.remove_reply_record(fid, comment_tid)
                logger.debug(f"å·²æ¸…ç†åˆ é™¤çš„å›å¤è®°å½•: feed_id={fid}, comment_id={comment_tid}")

    async def _process_single_feed(self, feed: dict, api_client: dict, target_qq: str, target_name: str) -> dict:
        """å¤„ç†å•æ¡è¯´è¯´ï¼Œå†³å®šæ˜¯å¦è¯„è®ºå’Œç‚¹èµ

        è¿”å›:
            dict: {"liked": bool, "commented": bool}
        """
        content = feed.get("content", "")
        fid = feed.get("tid", "")
        # æ­£ç¡®æå–è½¬å‘å†…å®¹ï¼ˆrt_con å¯èƒ½æ˜¯å­—å…¸æˆ–å­—ç¬¦ä¸²ï¼‰
        rt_con = feed.get("rt_con", {}).get("content", "") if isinstance(feed.get("rt_con"), dict) else feed.get("rt_con", "")
        images = feed.get("images", [])

        result = {"liked": False, "commented": False}

        # --- å¤„ç†è¯„è®º ---
        comment_key = f"{fid}_main_comment"
        should_comment = random.random() <= self.get_config("read.comment_possibility", 0.3)

        if (
            should_comment
            and not self.reply_tracker.has_replied(fid, "main_comment")
            and comment_key not in self.processing_comments
        ):
            logger.debug(f"é”å®šå¾…è¯„è®ºè¯´è¯´: {comment_key}")
            self.processing_comments.add(comment_key)
            try:
                # ä½¿ç”¨ç©ºé—´ä¸“ç”¨è¯„è®ºæ–¹æ³•
                comment_text = await self.content_service.generate_qzone_comment(
                    target_name=target_name,
                    content=content or rt_con or "è¯´è¯´å†…å®¹",
                    rt_con=rt_con if content else None,
                    images=images,
                    target_qq=target_qq,
                )
                if comment_text:
                    success = await api_client["comment"](target_qq, fid, comment_text)
                    if success:
                        self.reply_tracker.mark_as_replied(fid, "main_comment")
                        logger.info(f"æˆåŠŸè¯„è®º'{target_name}'çš„è¯´è¯´: '{comment_text}'")
                        result["commented"] = True
                    else:
                        logger.error(f"è¯„è®º'{target_name}'çš„è¯´è¯´å¤±è´¥")
            except Exception as e:
                logger.error(f"è¯„è®º'{target_name}'çš„è¯´è¯´æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            finally:
                logger.debug(f"è§£é”è¯´è¯´: {comment_key}")
                if comment_key in self.processing_comments:
                    self.processing_comments.remove(comment_key)

        # --- å¤„ç†ç‚¹èµ (é€»è¾‘ä¸å˜) ---
        like_probability = self.get_config("read.like_possibility", 1.0)
        if random.random() <= like_probability:
            logger.info(f"å‡†å¤‡ç‚¹èµè¯´è¯´: target_qq={target_qq}, fid={fid}")
            like_success = await api_client["like"](target_qq, fid)
            if like_success:
                logger.info(f"æˆåŠŸç‚¹èµ'{target_name}'çš„è¯´è¯´: fid={fid}")
                result["liked"] = True
            else:
                logger.warning(f"ç‚¹èµ'{target_name}'çš„è¯´è¯´å¤±è´¥: fid={fid}")
        else:
            logger.debug(f"æ¦‚ç‡æœªå‘½ä¸­ï¼Œè·³è¿‡ç‚¹èµ: probability={like_probability}")

        return result

    def _generate_gtk(self, skey: str) -> str:
        hash_val = 5381
        for char in skey:
            hash_val += (hash_val << 5) + ord(char)
        return str(hash_val & 2147483647)

    async def _renew_and_load_cookies(self, qq_account: str, stream_id: str | None) -> dict[str, str] | None:
        cookie_dir = Path(__file__).resolve().parent.parent / "cookies"
        cookie_dir.mkdir(exist_ok=True)
        cookie_file_path = cookie_dir / f"cookies-{qq_account}.json"

        # ä¼˜å…ˆå°è¯•é€šè¿‡Napcat HTTPæœåŠ¡è·å–æœ€æ–°çš„Cookie
        try:
            logger.info("å°è¯•é€šè¿‡Napcat HTTPæœåŠ¡è·å–Cookie...")
            host = self.get_config("cookie.http_fallback_host", "172.20.130.55")
            port = self.get_config("cookie.http_fallback_port", "9999")
            napcat_token = self.get_config("cookie.napcat_token", "")

            cookie_data = await self._fetch_cookies_http(host, port, napcat_token)
            if cookie_data and "cookies" in cookie_data:
                cookie_str = cookie_data["cookies"]
                parsed_cookies = {
                    k.strip(): v.strip() for k, v in (p.split("=", 1) for p in cookie_str.split("; ") if "=" in p)
                }
                # æˆåŠŸè·å–åï¼Œå¼‚æ­¥å†™å…¥æœ¬åœ°æ–‡ä»¶ä½œä¸ºå¤‡ä»½
                try:
                    async with aiofiles.open(cookie_file_path, "wb") as f:
                        await f.write(orjson.dumps(parsed_cookies))
                    logger.info(f"é€šè¿‡NapcatæœåŠ¡æˆåŠŸæ›´æ–°Cookieï¼Œå¹¶å·²ä¿å­˜è‡³: {cookie_file_path}")
                except Exception as e:
                    logger.warning(f"ä¿å­˜Cookieåˆ°æ–‡ä»¶æ—¶å‡ºé”™: {e}")
                return parsed_cookies
            else:
                logger.warning("é€šè¿‡NapcatæœåŠ¡æœªèƒ½è·å–æœ‰æ•ˆCookieã€‚")

        except Exception as e:
            logger.warning(f"é€šè¿‡Napcat HTTPæœåŠ¡è·å–Cookieæ—¶å‘ç”Ÿå¼‚å¸¸: {e}ã€‚å°†å°è¯•ä»æœ¬åœ°æ–‡ä»¶åŠ è½½ã€‚")

        # å¦‚æœé€šè¿‡æœåŠ¡è·å–å¤±è´¥ï¼Œåˆ™å°è¯•ä»æœ¬åœ°æ–‡ä»¶åŠ è½½
        logger.info("å°è¯•ä»æœ¬åœ°Cookieæ–‡ä»¶åŠ è½½...")
        if cookie_file_path.exists():
            try:
                async with aiofiles.open(cookie_file_path, "rb") as f:
                    content = await f.read()
                    cookies = orjson.loads(content)
                    logger.info(f"æˆåŠŸä»æœ¬åœ°æ–‡ä»¶åŠ è½½Cookie: {cookie_file_path}")
                    return cookies
            except Exception as e:
                logger.error(f"ä»æœ¬åœ°æ–‡ä»¶ {cookie_file_path} è¯»å–æˆ–è§£æCookieå¤±è´¥: {e}")
        else:
            logger.warning(f"æœ¬åœ°Cookieæ–‡ä»¶ä¸å­˜åœ¨: {cookie_file_path}")

        logger.error("æ‰€æœ‰è·å–Cookieçš„æ–¹å¼å‡å¤±è´¥ã€‚")
        return None

    async def _fetch_cookies_http(self, host: str, port: int, napcat_token: str) -> dict | None:
        """é€šè¿‡HTTPæœåŠ¡å™¨è·å–Cookie"""
        # ä»é…ç½®ä¸­è¯»å–ä¸»æœºå’Œç«¯å£ï¼Œå¦‚æœæœªæä¾›åˆ™ä½¿ç”¨ä¼ å…¥çš„å‚æ•°
        final_host = self.get_config("cookie.http_fallback_host", host)
        final_port = self.get_config("cookie.http_fallback_port", port)
        url = f"http://{final_host}:{final_port}/get_cookies"

        max_retries = 5
        retry_delay = 1

        for attempt in range(max_retries):
            try:
                headers = {"Content-Type": "application/json"}
                if napcat_token:
                    headers["Authorization"] = f"Bearer {napcat_token}"

                payload = {"domain": "user.qzone.qq.com"}

                async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=30.0)) as session:
                    async with session.post(url, json=payload, headers=headers) as resp:
                        resp.raise_for_status()

                        if resp.status != 200:
                            error_msg = f"NapcatæœåŠ¡è¿”å›é”™è¯¯çŠ¶æ€ç : {resp.status}"
                            if resp.status == 403:
                                error_msg += " (TokenéªŒè¯å¤±è´¥)"
                            raise RuntimeError(error_msg)

                        data = await resp.json()
                        if data.get("status") != "ok" or "cookies" not in data.get("data", {}):
                            raise RuntimeError(f"è·å– cookie å¤±è´¥: {data}")
                        return data["data"]

            except aiohttp.ClientError as e:
                if attempt < max_retries - 1:
                    logger.warning(f"æ— æ³•è¿æ¥åˆ°NapcatæœåŠ¡(å°è¯• {attempt + 1}/{max_retries}): {url}ï¼Œé”™è¯¯: {e!s}")
                    await asyncio.sleep(retry_delay)
                    retry_delay *= 2
                    continue
                logger.error(f"æ— æ³•è¿æ¥åˆ°NapcatæœåŠ¡(æœ€ç»ˆå°è¯•): {url}ï¼Œé”™è¯¯: {e!s}")
                raise RuntimeError(f"æ— æ³•è¿æ¥åˆ°NapcatæœåŠ¡: {url}") from e
            except Exception as e:
                logger.error(f"è·å–cookieå¼‚å¸¸: {e!s}")
                raise

        raise RuntimeError(f"æ— æ³•è¿æ¥åˆ°NapcatæœåŠ¡: è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°({max_retries})")

    async def _get_api_client(self, qq_account: str, stream_id: str | None) -> dict | None:
        logger.debug(f"å¼€å§‹è·å–APIå®¢æˆ·ç«¯ï¼Œqq_account={qq_account}")
        cookies = await self.cookie_service.get_cookies(qq_account, stream_id)
        if not cookies:
            logger.error(
                "è·å–APIå®¢æˆ·ç«¯å¤±è´¥ï¼šæœªèƒ½è·å–åˆ°Cookieã€‚è¯·æ£€æŸ¥Napcatè¿æ¥æ˜¯å¦æ­£å¸¸ï¼Œæˆ–æ˜¯å¦å­˜åœ¨æœ‰æ•ˆçš„æœ¬åœ°Cookieæ–‡ä»¶ã€‚"
            )
            return None

        logger.debug(f"Cookieè·å–æˆåŠŸï¼Œkeys: {list(cookies.keys())}")

        p_skey = cookies.get("p_skey") or cookies.get("p_skey".upper())
        if not p_skey:
            logger.error(f"è·å–APIå®¢æˆ·ç«¯å¤±è´¥ï¼šCookieä¸­ç¼ºå°‘å…³é”®çš„ 'p_skey'ã€‚Cookieå†…å®¹: {cookies}")
            return None

        logger.debug("p_skeyè·å–æˆåŠŸ")

        gtk = self._generate_gtk(p_skey)
        uin = cookies.get("uin", "").lstrip("o")
        if not uin:
            logger.error(f"è·å–APIå®¢æˆ·ç«¯å¤±è´¥ï¼šCookieä¸­ç¼ºå°‘å…³é”®çš„ 'uin'ã€‚Cookieå†…å®¹: {cookies}")
            return None

        logger.debug(f"uin={uin}, gtk={gtk}, å‡†å¤‡æ„é€ APIå®¢æˆ·ç«¯")

        async def _request(method, url, params=None, data=None, headers=None):
            final_headers = {"referer": f"https://user.qzone.qq.com/{uin}", "origin": "https://user.qzone.qq.com"}
            if headers:
                final_headers.update(headers)

            async with aiohttp.ClientSession(cookies=cookies) as session:
                timeout = aiohttp.ClientTimeout(total=20)
                async with session.request(
                    method, url, params=params, data=data, headers=final_headers, timeout=timeout
                ) as response:
                    response.raise_for_status()
                    return await response.text()

        async def _publish(content: str, images: list[bytes]) -> tuple[bool, str]:
            """å‘å¸ƒè¯´è¯´"""
            try:
                post_data = {
                    "syn_tweet_verson": "1",
                    "paramstr": "1",
                    "who": "1",
                    "con": content,
                    "feedversion": "1",
                    "ver": "1",
                    "ugc_right": "1",
                    "to_sign": "0",
                    "hostuin": uin,
                    "code_version": "1",
                    "format": "json",
                    "qzreferrer": f"https://user.qzone.qq.com/{uin}",
                }

                # å¤„ç†å›¾ç‰‡ä¸Šä¼ 
                if images:
                    logger.info(f"å¼€å§‹ä¸Šä¼  {len(images)} å¼ å›¾ç‰‡...")
                    pic_bos = []
                    richvals = []

                    for i, img_bytes in enumerate(images):
                        try:
                            # ä¸Šä¼ å›¾ç‰‡åˆ°QQç©ºé—´
                            upload_result = await _upload_image(img_bytes, i)
                            if upload_result:
                                pic_bos.append(upload_result["pic_bo"])
                                richvals.append(upload_result["richval"])
                                logger.info(f"å›¾ç‰‡ {i + 1} ä¸Šä¼ æˆåŠŸ")
                            else:
                                logger.error(f"å›¾ç‰‡ {i + 1} ä¸Šä¼ å¤±è´¥")
                        except Exception as e:
                            logger.error(f"ä¸Šä¼ å›¾ç‰‡ {i + 1} æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")

                    if pic_bos and richvals:
                        # å®Œå…¨æŒ‰ç…§åŸç‰ˆæ ¼å¼è®¾ç½®å›¾ç‰‡å‚æ•°
                        post_data["pic_bo"] = ",".join(pic_bos)
                        post_data["richtype"] = "1"
                        post_data["richval"] = "\t".join(richvals)  # åŸç‰ˆä½¿ç”¨åˆ¶è¡¨ç¬¦åˆ†éš”

                        logger.info(f"å‡†å¤‡å‘å¸ƒå¸¦å›¾è¯´è¯´: {len(pic_bos)} å¼ å›¾ç‰‡")
                        logger.info(f"pic_boå‚æ•°: {post_data['pic_bo']}")
                        logger.info(f"richvalå‚æ•°é•¿åº¦: {len(post_data['richval'])} å­—ç¬¦")
                    else:
                        logger.warning("æ‰€æœ‰å›¾ç‰‡ä¸Šä¼ å¤±è´¥ï¼Œå°†å‘å¸ƒçº¯æ–‡æœ¬è¯´è¯´")

                res_text = await _request("POST", self.EMOTION_PUBLISH_URL, params={"g_tk": gtk}, data=post_data)
                result = orjson.loads(res_text)
                tid = result.get("tid", "")

                if tid:
                    if images and pic_bos:
                        logger.info(f"æˆåŠŸå‘å¸ƒå¸¦å›¾è¯´è¯´ï¼Œtid: {tid}ï¼ŒåŒ…å« {len(pic_bos)} å¼ å›¾ç‰‡")
                    else:
                        logger.info(f"æˆåŠŸå‘å¸ƒæ–‡æœ¬è¯´è¯´ï¼Œtid: {tid}")
                else:
                    logger.error(f"å‘å¸ƒè¯´è¯´å¤±è´¥ï¼ŒAPIè¿”å›: {result}")

                return bool(tid), tid
            except Exception as e:
                logger.error(f"å‘å¸ƒè¯´è¯´å¼‚å¸¸: {e}")
                return False, ""

        def _image_to_base64(image_bytes: bytes) -> str:
            """å°†å›¾ç‰‡å­—èŠ‚è½¬æ¢ä¸ºbase64å­—ç¬¦ä¸²ï¼ˆä»¿ç…§åŸç‰ˆå®ç°ï¼‰"""
            pic_base64 = base64.b64encode(image_bytes)
            return str(pic_base64)[2:-1]  # å»æ‰ b'...' çš„å‰ç¼€å’Œåç¼€

        def _get_picbo_and_richval(upload_result: dict) -> tuple:
            """ä»ä¸Šä¼ ç»“æœä¸­æå–å›¾ç‰‡çš„picboå’Œrichvalå€¼ï¼ˆä»¿ç…§åŸç‰ˆå®ç°ï¼‰"""
            json_data = upload_result

            if "ret" not in json_data:
                raise Exception("è·å–å›¾ç‰‡picboå’Œrichvalå¤±è´¥")

            if json_data["ret"] != 0:
                raise Exception("ä¸Šä¼ å›¾ç‰‡å¤±è´¥")

            # ä»URLä¸­æå–boå‚æ•°
            picbo_spt = json_data["data"]["url"].split("&bo=")
            if len(picbo_spt) < 2:
                raise Exception("ä¸Šä¼ å›¾ç‰‡å¤±è´¥")
            picbo = picbo_spt[1]

            # æ„é€ richval - å®Œå…¨æŒ‰ç…§åŸç‰ˆæ ¼å¼
            richval = ",{},{},{},{},{},{},,{},{}".format(
                json_data["data"]["albumid"],
                json_data["data"]["lloc"],
                json_data["data"]["sloc"],
                json_data["data"]["type"],
                json_data["data"]["height"],
                json_data["data"]["width"],
                json_data["data"]["height"],
                json_data["data"]["width"],
            )

            return picbo, richval

        async def _upload_image(image_bytes: bytes, index: int) -> dict[str, str] | None:
            """ä¸Šä¼ å›¾ç‰‡åˆ°QQç©ºé—´ï¼ˆå®Œå…¨æŒ‰ç…§åŸç‰ˆå®ç°ï¼‰"""
            try:
                upload_url = "https://up.qzone.qq.com/cgi-bin/upload/cgi_upload_image"

                # å®Œå…¨æŒ‰ç…§åŸç‰ˆæ„å»ºè¯·æ±‚æ•°æ®
                post_data = {
                    "filename": "filename",
                    "zzpanelkey": "",
                    "uploadtype": "1",
                    "albumtype": "7",
                    "exttype": "0",
                    "skey": cookies.get("skey", ""),
                    "zzpaneluin": uin,
                    "p_uin": uin,
                    "uin": uin,
                    "p_skey": cookies.get("p_skey", ""),
                    "output_type": "json",
                    "qzonetoken": "",
                    "refer": "shuoshuo",
                    "charset": "utf-8",
                    "output_charset": "utf-8",
                    "upload_hd": "1",
                    "hd_width": "2048",
                    "hd_height": "10000",
                    "hd_quality": "96",
                    "backUrls": "http://upbak.photo.qzone.qq.com/cgi-bin/upload/cgi_upload_image,"
                    "http://119.147.64.75/cgi-bin/upload/cgi_upload_image",
                    "url": f"https://up.qzone.qq.com/cgi-bin/upload/cgi_upload_image?g_tk={gtk}",
                    "base64": "1",
                    "picfile": _image_to_base64(image_bytes),
                }

                headers = {"referer": f"https://user.qzone.qq.com/{uin}", "origin": "https://user.qzone.qq.com"}

                logger.info(f"å¼€å§‹ä¸Šä¼ å›¾ç‰‡ {index + 1}...")

                async with aiohttp.ClientSession(cookies=cookies) as session:
                    timeout = aiohttp.ClientTimeout(total=60)
                    async with session.post(upload_url, data=post_data, headers=headers, timeout=timeout) as response:
                        if response.status == 200:
                            resp_text = await response.text()
                            logger.info(f"å›¾ç‰‡ä¸Šä¼ å“åº”çŠ¶æ€ç : {response.status}")
                            logger.info(f"å›¾ç‰‡ä¸Šä¼ å“åº”å†…å®¹å‰500å­—ç¬¦: {resp_text[:500]}")

                            # æŒ‰ç…§åŸç‰ˆæ–¹å¼è§£æå“åº”
                            start_idx = resp_text.find("{")
                            end_idx = resp_text.rfind("}") + 1
                            if start_idx != -1 and end_idx != -1:
                                json_str = resp_text[start_idx:end_idx]
                                try:
                                    upload_result = orjson.loads(json_str)
                                except orjson.JSONDecodeError:
                                    logger.error(f"å›¾ç‰‡ä¸Šä¼ å“åº”JSONè§£æå¤±è´¥ï¼ŒåŸå§‹å“åº”: {resp_text}")
                                    return None

                                logger.debug(f"å›¾ç‰‡ä¸Šä¼ è§£æç»“æœ: {upload_result}")

                                if upload_result.get("ret") == 0:
                                    try:
                                        # ä½¿ç”¨åŸç‰ˆçš„å‚æ•°æå–é€»è¾‘
                                        picbo, richval = _get_picbo_and_richval(upload_result)
                                        logger.info(f"å›¾ç‰‡ {index + 1} ä¸Šä¼ æˆåŠŸ: picbo={picbo}")
                                        return {"pic_bo": picbo, "richval": richval}
                                    except Exception as e:
                                        logger.error(
                                            f"ä»ä¸Šä¼ ç»“æœä¸­æå–å›¾ç‰‡å‚æ•°å¤±è´¥: {e}, ä¸Šä¼ ç»“æœ: {upload_result}",
                                            exc_info=True,
                                        )
                                        return None
                                else:
                                    logger.error(f"å›¾ç‰‡ {index + 1} ä¸Šä¼ å¤±è´¥: {upload_result}")
                                    return None
                            else:
                                logger.error(f"æ— æ³•ä»å“åº”ä¸­æå–JSONå†…å®¹: {resp_text}")
                                return None
                        else:
                            error_text = await response.text()
                            logger.error(f"å›¾ç‰‡ä¸Šä¼ HTTPè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}, å“åº”: {error_text[:200]}")
                            return None

            except Exception as e:
                logger.error(f"ä¸Šä¼ å›¾ç‰‡ {index + 1} å¼‚å¸¸: {e}")
                return None

        async def _list_feeds(t_qq: str, num: int) -> list[dict]:
            """è·å–æŒ‡å®šç”¨æˆ·è¯´è¯´åˆ—è¡¨ (ç»Ÿä¸€æ¥å£)"""
            try:
                logger.debug(f"_list_feeds å¼€å§‹ï¼Œt_qq={t_qq}, num={num}")
                # ç»Ÿä¸€ä½¿ç”¨ format=json è·å–å®Œæ•´è¯„è®º
                params = {
                    "g_tk": gtk,
                    "uin": t_qq,
                    "ftype": 0,
                    "sort": 0,
                    "pos": 0,
                    "num": num,
                    "replynum": 999,  # å°½é‡è·å–æ›´å¤š
                    "code_version": 1,
                    "format": "json",  # å…³é”®ï¼šä½¿ç”¨JSONæ ¼å¼
                    "need_comment": 1,
                }
                logger.debug(f"å‡†å¤‡å‘é€HTTPè¯·æ±‚åˆ° {self.LIST_URL}")
                res_text = await _request("GET", self.LIST_URL, params=params)
                logger.debug(f"HTTPè¯·æ±‚è¿”å›ï¼Œå“åº”é•¿åº¦={len(res_text)}")
                json_data = orjson.loads(res_text)
                logger.debug(f"JSONè§£ææˆåŠŸï¼Œcode={json_data.get('code')}")
                if json_data.get("code") != 0:
                    error_code = json_data.get("code")
                    error_message = json_data.get("message", "æœªçŸ¥é”™è¯¯")
                    logger.warning(f"è·å–è¯´è¯´åˆ—è¡¨APIè¿”å›é”™è¯¯: code={error_code}, message={error_message}")

                    # å°†APIé”™è¯¯ä¿¡æ¯æŠ›å‡ºï¼Œè®©ä¸Šå±‚å¤„ç†å¹¶åé¦ˆç»™ç”¨æˆ·
                    raise RuntimeError(f"QQç©ºé—´APIé”™è¯¯: {error_message} (é”™è¯¯ç : {error_code})")

                feeds_list = []
                my_name = json_data.get("logininfo", {}).get("name", "")
                total_msgs = len(json_data.get("msglist", []))
                logger.debug(f"[DEBUG] ä»APIè·å–åˆ° {total_msgs} æ¡åŸå§‹è¯´è¯´")

                for idx, msg in enumerate(json_data.get("msglist", [])):
                    msg_tid = msg.get("tid", "")
                    msg_content = msg.get("content", "")
                    msg_rt_con = msg.get("rt_con")
                    is_retweet = bool(msg_rt_con)

                    logger.debug(f"[DEBUG] è¯´è¯´ {idx+1}/{total_msgs}: tid={msg_tid}, æ˜¯å¦è½¬å‘={is_retweet}, contenté•¿åº¦={len(msg_content)}")

                    # å½“è¯»å–çš„æ˜¯å¥½å‹åŠ¨æ€æ—¶ï¼Œæ£€æŸ¥æ˜¯å¦å·²è¯„è®ºè¿‡ï¼Œå¦‚æœæ˜¯åˆ™è·³è¿‡
                    is_friend_feed = str(t_qq) != str(uin)
                    if is_friend_feed:
                        commentlist_for_check = msg.get("commentlist")
                        is_commented = False
                        if isinstance(commentlist_for_check, list):
                            is_commented = any(
                                c.get("name") == my_name for c in commentlist_for_check if isinstance(c, dict)
                            )
                        if is_commented:
                            logger.debug(f"[DEBUG] è·³è¿‡å·²è¯„è®ºçš„è¯´è¯´: tid={msg_tid}, æ˜¯å¦è½¬å‘={is_retweet}")
                            continue

                    # --- å®‰å…¨åœ°å¤„ç†å›¾ç‰‡åˆ—è¡¨ ---
                    images = []
                    if "pic" in msg and isinstance(msg["pic"], list):
                        images = [pic.get("url1", "") for pic in msg["pic"] if pic.get("url1")]
                    elif "pictotal" in msg and isinstance(msg["pictotal"], list):
                        images = [pic.get("url1", "") for pic in msg["pictotal"] if pic.get("url1")]

                    # --- è§£æå®Œæ•´è¯„è®ºåˆ—è¡¨ (åŒ…æ‹¬äºŒçº§è¯„è®º) ---
                    comments = []
                    commentlist = msg.get("commentlist")
                    if isinstance(commentlist, list):
                        for c in commentlist:
                            if not isinstance(c, dict):
                                continue

                            # æ·»åŠ ä¸»è¯„è®º
                            comments.append(
                                {
                                    "qq_account": c.get("uin"),
                                    "nickname": c.get("name"),
                                    "content": c.get("content"),
                                    "comment_tid": c.get("tid"),
                                    "parent_tid": None,  # ä¸»è¯„è®ºæ²¡æœ‰çˆ¶ID
                                }
                            )
                            # æ£€æŸ¥å¹¶æ·»åŠ äºŒçº§è¯„è®º (å›å¤)
                            if "list_3" in c and isinstance(c["list_3"], list):
                                for reply in c["list_3"]:
                                    if not isinstance(reply, dict):
                                        continue
                                    comments.append(
                                        {
                                            "qq_account": reply.get("uin"),
                                            "nickname": reply.get("name"),
                                            "content": reply.get("content"),
                                            "comment_tid": reply.get("tid"),
                                            "parent_tid": c.get("tid"),  # çˆ¶IDæ˜¯ä¸»è¯„è®ºçš„ID
                                        }
                                    )

                    feeds_list.append(
                        {
                            "tid": msg.get("tid", ""),
                            "content": msg.get("content", ""),
                            "created_time": time.strftime(
                                "%Y-%m-%d %H:%M:%S", time.localtime(msg.get("created_time", 0))
                            ),
                            "rt_con": msg.get("rt_con", {}).get("content", "")
                            if isinstance(msg.get("rt_con"), dict)
                            else "",
                            "images": images,
                            "comments": comments,
                        }
                    )

                logger.info(f"æˆåŠŸè·å–åˆ° {len(feeds_list)} æ¡è¯´è¯´ from {t_qq} (ä½¿ç”¨ç»Ÿä¸€JSONæ¥å£)")
                return feeds_list
            except RuntimeError:
                # QQç©ºé—´APIä¸šåŠ¡é”™è¯¯ï¼Œå‘ä¸Šä¼ æ’­è®©è°ƒç”¨è€…å¤„ç†
                raise
            except Exception as e:
                # å…¶ä»–å¼‚å¸¸ï¼ˆå¦‚ç½‘ç»œé”™è¯¯ã€JSONè§£æé”™è¯¯ç­‰ï¼‰ï¼Œè®°å½•åè¿”å›ç©ºåˆ—è¡¨
                logger.error(f"è·å–è¯´è¯´åˆ—è¡¨å¤±è´¥: {e}")
                return []

        async def _comment(t_qq: str, feed_id: str, text: str) -> bool:
            """è¯„è®ºè¯´è¯´"""
            try:
                data = {
                    "topicId": f"{t_qq}_{feed_id}__1",
                    "uin": uin,
                    "hostUin": t_qq,
                    "content": text,
                    "format": "fs",
                    "plat": "qzone",
                    "source": "ic",
                    "platformid": 52,
                    "ref": "feeds",
                }
                response_text = await _request("POST", self.COMMENT_URL, params={"g_tk": gtk}, data=data)

                # è§£æå“åº”æ£€æŸ¥ä¸šåŠ¡çŠ¶æ€
                try:
                    response_data = orjson.loads(response_text)
                    code = response_data.get("code", -1)
                    if code == 0:
                        logger.info(f"è¯„è®ºAPIè¿”å›æˆåŠŸ: feed_id={feed_id}")
                        return True
                    else:
                        message = response_data.get("message", "æœªçŸ¥é”™è¯¯")
                        logger.error(f"è¯„è®ºAPIè¿”å›å¤±è´¥: code={code}, message={message}, feed_id={feed_id}")
                        return False
                except orjson.JSONDecodeError:
                    logger.warning(f"è¯„è®ºAPIå“åº”æ— æ³•è§£æä¸ºJSONï¼Œå‡å®šæˆåŠŸ: {response_text[:200]}")
                    return True
            except Exception as e:
                logger.error(f"è¯„è®ºè¯´è¯´å¼‚å¸¸: {e}")
                return False

        async def _like(t_qq: str, feed_id: str) -> bool:
            """ç‚¹èµè¯´è¯´"""
            try:
                data = {
                    "opuin": uin,
                    "unikey": f"http://user.qzone.qq.com/{t_qq}/mood/{feed_id}",
                    "curkey": f"http://user.qzone.qq.com/{t_qq}/mood/{feed_id}",
                    "from": 1,
                    "appid": 311,
                    "typeid": 0,
                    "abstime": int(time.time()),
                    "fid": feed_id,
                    "active": 0,
                    "format": "json",
                    "fupdate": 1,
                }
                response_text = await _request("POST", self.DOLIKE_URL, params={"g_tk": gtk}, data=data)

                # è§£æå“åº”æ£€æŸ¥ä¸šåŠ¡çŠ¶æ€
                try:
                    response_data = orjson.loads(response_text)
                    code = response_data.get("code", -1)
                    if code == 0:
                        logger.debug(f"ç‚¹èµAPIè¿”å›æˆåŠŸ: feed_id={feed_id}")
                        return True
                    else:
                        message = response_data.get("message", "æœªçŸ¥é”™è¯¯")
                        logger.warning(f"ç‚¹èµAPIè¿”å›å¤±è´¥: code={code}, message={message}, feed_id={feed_id}")
                        return False
                except orjson.JSONDecodeError:
                    logger.warning(f"ç‚¹èµAPIå“åº”æ— æ³•è§£æä¸ºJSONï¼Œå‡å®šæˆåŠŸ: {response_text[:200]}")
                    return True
            except Exception as e:
                logger.error(f"ç‚¹èµè¯´è¯´å¼‚å¸¸: {e}")
                return False

        async def _reply(fid, host_qq, target_name, content, comment_tid):
            """å›å¤è¯„è®º - ä¿®å¤ä¸ºèƒ½æ­£ç¡®æé†’çš„å›å¤æ ¼å¼"""
            try:
                # ä¿®å¤å›å¤é€»è¾‘ï¼šç¡®ä¿èƒ½æ­£ç¡®æé†’è¢«å›å¤çš„äºº
                data = {
                    "topicId": f"{host_qq}_{fid}__1",
                    "parent_tid": comment_tid,
                    "uin": uin,
                    "hostUin": host_qq,
                    "content": content,
                    "format": "fs",
                    "plat": "qzone",
                    "source": "ic",
                    "platformid": 52,
                    "ref": "feeds",
                    "richtype": "",
                    "richval": "",
                    "paramstr": "",
                }

                # è®°å½•è¯¦ç»†çš„è¯·æ±‚å‚æ•°ç”¨äºè°ƒè¯•
                logger.info(
                    f"å­å›å¤è¯·æ±‚å‚æ•°: topicId={data['topicId']}, parent_tid={data['parent_tid']}, content='{content[:50]}...'"
                )

                response_text = await _request("POST", self.REPLY_URL, params={"g_tk": gtk}, data=data)

                # è§£æå“åº”æ£€æŸ¥ä¸šåŠ¡çŠ¶æ€
                try:
                    response_data = orjson.loads(response_text)
                    code = response_data.get("code", -1)
                    if code == 0:
                        logger.info(f"å›å¤APIè¿”å›æˆåŠŸ: fid={fid}, parent_tid={comment_tid}")
                        return True
                    else:
                        message = response_data.get("message", "æœªçŸ¥é”™è¯¯")
                        logger.error(f"å›å¤APIè¿”å›å¤±è´¥: code={code}, message={message}, fid={fid}")
                        return False
                except orjson.JSONDecodeError:
                    logger.warning(f"å›å¤APIå“åº”æ— æ³•è§£æä¸ºJSONï¼Œå‡å®šæˆåŠŸ: {response_text[:200]}")
                    return True
            except Exception as e:
                logger.error(f"å›å¤è¯„è®ºå¼‚å¸¸: {e}")
                return False

        async def _monitor_list_feeds(num: int) -> list[dict]:
            """ç›‘æ§å¥½å‹åŠ¨æ€"""
            try:
                params = {
                    "uin": uin,
                    "scope": 0,
                    "view": 1,
                    "filter": "all",
                    "flag": 1,
                    "applist": "all",
                    "pagenum": 1,
                    "count": num,
                    "format": "json",
                    "g_tk": gtk,
                    "useutf8": 1,
                    "outputhtmlfeed": 1,
                }
                res_text = await _request("GET", self.ZONE_LIST_URL, params=params)

                # å¤„ç†ä¸åŒçš„å“åº”æ ¼å¼
                json_str = ""
                stripped_res_text = res_text.strip()
                if stripped_res_text.startswith("_Callback(") and stripped_res_text.endswith(");"):
                    json_str = stripped_res_text[len("_Callback(") : -2]
                elif stripped_res_text.startswith("{") and stripped_res_text.endswith("}"):
                    json_str = stripped_res_text
                else:
                    logger.warning(f"æ„å¤–çš„å“åº”æ ¼å¼: {res_text[:100]}...")
                    return []

                json_str = json_str.replace("undefined", "null").strip()

                # è§£æJSON
                try:
                    json_data = json5.loads(json_str)
                except Exception as parse_error:
                    logger.error(f"JSONè§£æå¤±è´¥: {parse_error}, åŸå§‹æ•°æ®: {json_str[:200]}...")
                    return []

                # æ£€æŸ¥JSONæ•°æ®ç±»å‹
                if not isinstance(json_data, dict):
                    logger.warning(f"è§£æåçš„JSONæ•°æ®ä¸æ˜¯å­—å…¸ç±»å‹: {type(json_data)}")
                    return []

                # æ£€æŸ¥é”™è¯¯ç ï¼ˆåœ¨try-exceptä¹‹å¤–ï¼Œè®©å¼‚å¸¸èƒ½å‘ä¸Šä¼ æ’­ï¼‰
                if json_data.get("code") != 0:
                    error_code = json_data.get("code")
                    error_msg = json_data.get("message", "æœªçŸ¥é”™è¯¯")
                    logger.warning(f"QQç©ºé—´APIè¿”å›é”™è¯¯: code={error_code}, message={error_msg}")
                    # æŠ›å‡ºå¼‚å¸¸ä»¥ä¾¿ä¸Šå±‚çš„é‡è¯•æœºåˆ¶æ•è·
                    raise RuntimeError(f"QQç©ºé—´APIé”™è¯¯: {error_msg} (é”™è¯¯ç : {error_code})")

                feeds_data = []
                if isinstance(json_data, dict):
                    data_level1 = json_data.get("data")
                    if isinstance(data_level1, dict):
                        feeds_data = data_level1.get("data", [])

                feeds_list = []
                for feed in feeds_data:
                    if not feed or not isinstance(feed, dict):
                        continue

                    if str(feed.get("appid", "")) != "311":
                        continue

                    target_qq = str(feed.get("uin", ""))
                    tid = feed.get("key", "")
                    if not target_qq or not tid:
                        continue

                    if target_qq == str(uin):
                        continue

                    html_content = feed.get("html", "")
                    if not html_content:
                        continue

                    soup = bs4.BeautifulSoup(html_content, "html.parser")

                    like_btn = soup.find("a", class_="qz_like_btn_v3")
                    is_liked = False
                    if isinstance(like_btn, bs4.Tag) and like_btn.get("data-islike") == "1":
                        is_liked = True

                    if is_liked:
                        continue

                    text_div = soup.find("div", class_="f-info")
                    text = text_div.get_text(strip=True) if isinstance(text_div, bs4.Tag) else ""

                    # --- å€Ÿé‰´åŸç‰ˆæ’ä»¶çš„ç²¾ç¡®å›¾ç‰‡æå–é€»è¾‘ ---
                    image_urls = []
                    img_box = soup.find("div", class_="img-box")
                    if isinstance(img_box, bs4.Tag):
                        for img in img_box.find_all("img"):
                            if isinstance(img, bs4.Tag):
                                src = img.get("src")
                                if src and isinstance(src, str) and "qzonestyle.gtimg.cn" not in src:
                                    image_urls.append(src)

                    # è§†é¢‘å°é¢ä¹Ÿè§†ä¸ºå›¾ç‰‡
                    video_thumb = soup.select_one("div.video-img img")
                    if isinstance(video_thumb, bs4.Tag) and "src" in video_thumb.attrs:
                        image_urls.append(video_thumb["src"])

                    # å»é‡
                    images = list(set(image_urls))

                    comments = []
                    comment_divs = soup.find_all("div", class_="f-single-comment")
                    for comment_div in comment_divs:
                        if not isinstance(comment_div, bs4.Tag):
                            continue
                        # --- å¤„ç†ä¸»è¯„è®º ---
                        author_a = comment_div.find("a", class_="f-nick")
                        content_span = comment_div.find("span", class_="f-re-con")

                        if isinstance(author_a, bs4.Tag) and isinstance(content_span, bs4.Tag):
                            comments.append(
                                {
                                    "qq_account": str(comment_div.get("data-uin", "")),
                                    "nickname": author_a.get_text(strip=True),
                                    "content": content_span.get_text(strip=True),
                                    "comment_tid": comment_div.get("data-tid", ""),
                                    "parent_tid": None,  # ä¸»è¯„è®ºæ²¡æœ‰çˆ¶ID
                                }
                            )

                        # --- å¤„ç†è¿™æ¡ä¸»è¯„è®ºä¸‹çš„æ‰€æœ‰å›å¤ ---
                        reply_divs = comment_div.find_all("div", class_="f-single-re")
                        for reply_div in reply_divs:
                            if not isinstance(reply_div, bs4.Tag):
                                continue
                            reply_author_a = reply_div.find("a", class_="f-nick")
                            reply_content_span = reply_div.find("span", class_="f-re-con")

                            if isinstance(reply_author_a, bs4.Tag) and isinstance(reply_content_span, bs4.Tag):
                                comments.append(
                                    {
                                        "qq_account": str(reply_div.get("data-uin", "")),
                                        "nickname": reply_author_a.get_text(strip=True),
                                        "content": reply_content_span.get_text(strip=True).lstrip(
                                            ": "
                                        ),
                                        "comment_tid": reply_div.get("data-tid", ""),
                                        "parent_tid": reply_div.get(
                                            "data-parent-tid", comment_div.get("data-tid", "")
                                        ),
                                    }
                                )

                    feeds_list.append(
                        {"target_qq": target_qq, "tid": tid, "content": text, "images": images, "comments": comments}
                    )
                logger.info(f"ç›‘æ§ä»»åŠ¡å‘ç° {len(feeds_list)} æ¡æœªå¤„ç†çš„æ–°è¯´è¯´ã€‚")
                return feeds_list
            except Exception as e:
                # æ£€æŸ¥æ˜¯å¦æ˜¯Cookieå¤±æ•ˆé”™è¯¯ï¼ˆ-3000ï¼‰ï¼Œå¦‚æœæ˜¯åˆ™é‡æ–°æŠ›å‡º
                if "é”™è¯¯ç : -3000" in str(e):
                    logger.warning("ç›‘æ§ä»»åŠ¡é‡åˆ°Cookieå¤±æ•ˆé”™è¯¯ï¼Œé‡æ–°æŠ›å‡ºå¼‚å¸¸ä»¥è§¦å‘ä¸Šå±‚é‡è¯•")
                    raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè®©ä¸Šå±‚å¤„ç†
                logger.error(f"ç›‘æ§å¥½å‹åŠ¨æ€å¤±è´¥: {e}")
                return []

        logger.debug("APIå®¢æˆ·ç«¯æ„é€ å®Œæˆï¼Œè¿”å›åŒ…å«6ä¸ªæ–¹æ³•çš„å­—å…¸")
        return {
            "publish": _publish,
            "list_feeds": _list_feeds,
            "comment": _comment,
            "like": _like,
            "reply": _reply,
            "monitor_list_feeds": _monitor_list_feeds,
        }
