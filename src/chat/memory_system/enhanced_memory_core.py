# -*- coding: utf-8 -*-
"""
å¢å¼ºå‹ç²¾å‡†è®°å¿†ç³»ç»Ÿæ ¸å¿ƒæ¨¡å—
åŸºäºæ–‡æ¡£è®¾è®¡çš„é«˜æ•ˆè®°å¿†æ„å»ºã€å­˜å‚¨ä¸å¬å›ä¼˜åŒ–ç³»ç»Ÿ
"""

import asyncio
import time
import orjson
import re
from typing import Dict, List, Optional, Set, Any, TYPE_CHECKING
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict
from enum import Enum
import numpy as np

from src.common.logger import get_logger
from src.llm_models.utils_model import LLMRequest
from src.config.config import model_config, global_config
from src.chat.memory_system.memory_chunk import MemoryChunk, MemoryType
from src.chat.memory_system.memory_builder import MemoryBuilder
from src.chat.memory_system.memory_fusion import MemoryFusionEngine
from src.chat.memory_system.vector_storage import VectorStorageManager, VectorStorageConfig
from src.chat.memory_system.metadata_index import MetadataIndexManager
from src.chat.memory_system.multi_stage_retrieval import MultiStageRetrieval, RetrievalConfig

if TYPE_CHECKING:
    from src.common.data_models.database_data_model import DatabaseMessages

logger = get_logger(__name__)


class MemorySystemStatus(Enum):
    """è®°å¿†ç³»ç»ŸçŠ¶æ€"""
    INITIALIZING = "initializing"
    READY = "ready"
    BUILDING = "building"
    RETRIEVING = "retrieving"
    ERROR = "error"


@dataclass
class MemorySystemConfig:
    """è®°å¿†ç³»ç»Ÿé…ç½®"""
    # è®°å¿†æ„å»ºé…ç½®
    min_memory_length: int = 10
    max_memory_length: int = 500
    memory_value_threshold: float = 0.7
    min_build_interval_seconds: float = 300.0

    # å‘é‡å­˜å‚¨é…ç½®
    vector_dimension: int = 768
    similarity_threshold: float = 0.8

    # å¬å›é…ç½®
    coarse_recall_limit: int = 50
    fine_recall_limit: int = 10
    final_recall_limit: int = 5

    # èåˆé…ç½®
    fusion_similarity_threshold: float = 0.85
    deduplication_window: timedelta = timedelta(hours=24)

    @classmethod
    def from_global_config(cls):
        """ä»å…¨å±€é…ç½®åˆ›å»ºé…ç½®å®ä¾‹"""
        from src.config.config import global_config

        return cls(
            # è®°å¿†æ„å»ºé…ç½®
            min_memory_length=global_config.memory.min_memory_length,
            max_memory_length=global_config.memory.max_memory_length,
            memory_value_threshold=global_config.memory.memory_value_threshold,
            min_build_interval_seconds=getattr(global_config.memory, "memory_build_interval", 300.0),

            # å‘é‡å­˜å‚¨é…ç½®
            vector_dimension=global_config.memory.vector_dimension,
            similarity_threshold=global_config.memory.vector_similarity_threshold,

            # å¬å›é…ç½®
            coarse_recall_limit=global_config.memory.metadata_filter_limit,
            fine_recall_limit=global_config.memory.final_result_limit,
            final_recall_limit=global_config.memory.final_result_limit,

            # èåˆé…ç½®
            fusion_similarity_threshold=global_config.memory.fusion_similarity_threshold,
            deduplication_window=timedelta(hours=global_config.memory.deduplication_window_hours)
        )


class EnhancedMemorySystem:
    """å¢å¼ºå‹ç²¾å‡†è®°å¿†ç³»ç»Ÿæ ¸å¿ƒç±»"""

    def __init__(
        self,
        llm_model: Optional[LLMRequest] = None,
        config: Optional[MemorySystemConfig] = None
    ):
        self.config = config or MemorySystemConfig.from_global_config()
        self.llm_model = llm_model
        self.status = MemorySystemStatus.INITIALIZING

        # æ ¸å¿ƒç»„ä»¶
        self.memory_builder: MemoryBuilder = None
        self.fusion_engine: MemoryFusionEngine = None
        self.vector_storage: VectorStorageManager = None
        self.metadata_index: MetadataIndexManager = None
        self.retrieval_system: MultiStageRetrieval = None

        # LLMæ¨¡å‹
        self.value_assessment_model: LLMRequest = None
        self.memory_extraction_model: LLMRequest = None

        # ç»Ÿè®¡ä¿¡æ¯
        self.total_memories = 0
        self.last_build_time = None
        self.last_retrieval_time = None

        # æ„å»ºèŠ‚æµè®°å½•
        self._last_memory_build_times: Dict[str, float] = {}

        logger.info("EnhancedMemorySystem åˆå§‹åŒ–å¼€å§‹")

    async def initialize(self):
        """å¼‚æ­¥åˆå§‹åŒ–è®°å¿†ç³»ç»Ÿ"""
        try:
            logger.info("æ­£åœ¨åˆå§‹åŒ–å¢å¼ºå‹è®°å¿†ç³»ç»Ÿ...")

            # åˆå§‹åŒ–LLMæ¨¡å‹
            task_config = (
                self.llm_model.model_for_task
                if self.llm_model is not None
                else model_config.model_task_config.utils
            )

            self.value_assessment_model = LLMRequest(
                model_set=task_config,
                request_type="memory.value_assessment"
            )

            self.memory_extraction_model = LLMRequest(
                model_set=task_config,
                request_type="memory.extraction"
            )

            # åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶
            self.memory_builder = MemoryBuilder(self.memory_extraction_model)
            self.fusion_engine = MemoryFusionEngine(self.config.fusion_similarity_threshold)
            # åˆ›å»ºå‘é‡å­˜å‚¨é…ç½®
            vector_config = VectorStorageConfig(
                dimension=self.config.vector_dimension,
                similarity_threshold=self.config.similarity_threshold
            )
            self.vector_storage = VectorStorageManager(vector_config)
            self.metadata_index = MetadataIndexManager()
            # åˆ›å»ºæ£€ç´¢é…ç½®
            retrieval_config = RetrievalConfig(
                metadata_filter_limit=self.config.coarse_recall_limit,
                vector_search_limit=self.config.fine_recall_limit,
                final_result_limit=self.config.final_recall_limit
            )
            self.retrieval_system = MultiStageRetrieval(retrieval_config)

            # åŠ è½½æŒä¹…åŒ–æ•°æ®
            await self.vector_storage.load_storage()
            await self.metadata_index.load_index()

            self.status = MemorySystemStatus.READY
            logger.info("âœ… å¢å¼ºå‹è®°å¿†ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")

        except Exception as e:
            self.status = MemorySystemStatus.ERROR
            logger.error(f"âŒ è®°å¿†ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
            raise

    async def build_memory_from_conversation(
        self,
        conversation_text: str,
        context: Dict[str, Any],
        user_id: str,
        timestamp: Optional[float] = None
    ) -> List[MemoryChunk]:
        """ä»å¯¹è¯ä¸­æ„å»ºè®°å¿†

        Args:
            conversation_text: å¯¹è¯æ–‡æœ¬
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆåŒ…æ‹¬ç”¨æˆ·ä¿¡æ¯ã€ç¾¤ç»„ä¿¡æ¯ç­‰ï¼‰
            user_id: ç”¨æˆ·ID
            timestamp: æ—¶é—´æˆ³ï¼Œé»˜è®¤ä¸ºå½“å‰æ—¶é—´

        Returns:
            æ„å»ºçš„è®°å¿†å—åˆ—è¡¨
        """
        if self.status != MemorySystemStatus.READY:
            raise RuntimeError("è®°å¿†ç³»ç»Ÿæœªå°±ç»ª")

        self.status = MemorySystemStatus.BUILDING
        start_time = time.time()

        build_scope_key: Optional[str] = None
        build_marker_time: Optional[float] = None

        try:
            normalized_context = self._normalize_context(context, user_id, timestamp)

            build_scope_key = self._get_build_scope_key(normalized_context, user_id)
            min_interval = max(0.0, getattr(self.config, "min_build_interval_seconds", 0.0))
            current_time = time.time()

            if build_scope_key and min_interval > 0:
                last_time = self._last_memory_build_times.get(build_scope_key)
                if last_time and (current_time - last_time) < min_interval:
                    remaining = min_interval - (current_time - last_time)
                    logger.info(
                        "è·ç¦»ä¸Šæ¬¡è®°å¿†æ„å»ºé—´éš”ä¸è¶³ï¼Œè·³è¿‡æ­¤æ¬¡æ„å»º | key=%s | å‰©ä½™%.2fç§’",
                        build_scope_key,
                        remaining,
                    )
                    self.status = MemorySystemStatus.READY
                    return []

                build_marker_time = current_time
                self._last_memory_build_times[build_scope_key] = current_time

            conversation_text = self._resolve_conversation_context(conversation_text, normalized_context)

            logger.debug(f"å¼€å§‹ä¸ºç”¨æˆ· {user_id} æ„å»ºè®°å¿†ï¼Œæ–‡æœ¬é•¿åº¦: {len(conversation_text)}")

            # 1. ä¿¡æ¯ä»·å€¼è¯„ä¼°
            value_score = await self._assess_information_value(conversation_text, normalized_context)

            if value_score < self.config.memory_value_threshold:
                logger.info(f"ä¿¡æ¯ä»·å€¼è¯„åˆ† {value_score:.2f} ä½äºé˜ˆå€¼ï¼Œè·³è¿‡è®°å¿†æ„å»º")
                self.status = MemorySystemStatus.READY
                return []

            # 2. æ„å»ºè®°å¿†å—
            memory_chunks = await self.memory_builder.build_memories(
                conversation_text,
                normalized_context,
                user_id,
                timestamp or time.time()
            )

            if not memory_chunks:
                logger.debug("æœªæå–åˆ°æœ‰æ•ˆè®°å¿†å—")
                self.status = MemorySystemStatus.READY
                return []

            # 3. è®°å¿†èåˆä¸å»é‡
            fused_chunks = await self.fusion_engine.fuse_memories(memory_chunks)

            # 4. å­˜å‚¨è®°å¿†
            await self._store_memories(fused_chunks)

            # 5. æ›´æ–°ç»Ÿè®¡
            self.total_memories += len(fused_chunks)
            self.last_build_time = time.time()
            if build_scope_key:
                self._last_memory_build_times[build_scope_key] = self.last_build_time

            build_time = time.time() - start_time
            logger.info(f"âœ… ä¸ºç”¨æˆ· {user_id} æ„å»ºäº† {len(fused_chunks)} æ¡è®°å¿†ï¼Œè€—æ—¶ {build_time:.2f}ç§’")

            self.status = MemorySystemStatus.READY
            return fused_chunks

        except Exception as e:
            if build_scope_key and build_marker_time is not None:
                recorded_time = self._last_memory_build_times.get(build_scope_key)
                if recorded_time == build_marker_time:
                    self._last_memory_build_times.pop(build_scope_key, None)
            self.status = MemorySystemStatus.ERROR
            logger.error(f"âŒ è®°å¿†æ„å»ºå¤±è´¥: {e}", exc_info=True)
            raise

    async def process_conversation_memory(
        self,
        conversation_text: str,
        context: Dict[str, Any],
        user_id: str,
        timestamp: Optional[float] = None
    ) -> Dict[str, Any]:
        """å¯¹å¤–æš´éœ²çš„å¯¹è¯è®°å¿†å¤„ç†æ¥å£ï¼Œå…¼å®¹æ—§è°ƒç”¨æ–¹å¼"""
        start_time = time.time()

        try:
            normalized_context = self._normalize_context(context, user_id, timestamp)

            memories = await self.build_memory_from_conversation(
                conversation_text=conversation_text,
                context=normalized_context,
                user_id=user_id,
                timestamp=timestamp
            )

            processing_time = time.time() - start_time
            memory_count = len(memories)

            return {
                "success": True,
                "created_memories": memories,
                "memory_count": memory_count,
                "processing_time": processing_time,
                "status": self.status.value
            }

        except Exception as e:
            processing_time = time.time() - start_time
            logger.error(f"å¯¹è¯è®°å¿†å¤„ç†å¤±è´¥: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "processing_time": processing_time,
                "status": self.status.value
            }

    async def retrieve_relevant_memories(
        self,
        query_text: Optional[str] = None,
        user_id: Optional[str] = None,
        context: Optional[Dict[str, Any]] = None,
        limit: int = 5,
        **kwargs
    ) -> List[MemoryChunk]:
        """æ£€ç´¢ç›¸å…³è®°å¿†ï¼Œå…¼å®¹ query/query_text å‚æ•°å½¢å¼"""
        if self.status != MemorySystemStatus.READY:
            raise RuntimeError("è®°å¿†ç³»ç»Ÿæœªå°±ç»ª")

        query_text = query_text or kwargs.get("query")
        if not query_text:
            raise ValueError("query_text æˆ– query å‚æ•°ä¸èƒ½ä¸ºç©º")

        context = context or {}
        user_id = user_id or kwargs.get("user_id")

        self.status = MemorySystemStatus.RETRIEVING
        start_time = time.time()

        try:
            normalized_context = self._normalize_context(context, user_id, None)

            candidate_memories = list(self.vector_storage.memory_cache.values())
            if user_id:
                candidate_memories = [m for m in candidate_memories if m.user_id == user_id]

            if not candidate_memories:
                self.status = MemorySystemStatus.READY
                self.last_retrieval_time = time.time()
                logger.debug(f"æœªæ‰¾åˆ°ç”¨æˆ· {user_id} çš„å€™é€‰è®°å¿†")
                return []

            scored_memories = []
            for memory in candidate_memories:
                score = self._compute_memory_score(query_text, memory, normalized_context)
                if score > 0:
                    scored_memories.append((memory, score))

            if not scored_memories:
                # å¦‚æœæ‰€æœ‰åˆ†æ•°ä¸º0ï¼Œè¿”å›æœ€è¿‘çš„è®°å¿†ä½œä¸ºé™çº§ç­–ç•¥
                candidate_memories.sort(key=lambda m: m.metadata.last_accessed, reverse=True)
                scored_memories = [(memory, 0.0) for memory in candidate_memories[:limit]]
            else:
                scored_memories.sort(key=lambda item: item[1], reverse=True)

            top_memories = [memory for memory, _ in scored_memories[:limit]]

            # æ›´æ–°è®¿é—®ä¿¡æ¯å’Œç¼“å­˜
            for memory, score in scored_memories[:limit]:
                memory.update_access()
                memory.update_relevance(score)

                cache_entry = self.metadata_index.memory_metadata_cache.get(memory.memory_id)
                if cache_entry is not None:
                    cache_entry["last_accessed"] = memory.metadata.last_accessed
                    cache_entry["access_count"] = memory.metadata.access_count
                    cache_entry["relevance_score"] = memory.metadata.relevance_score

            retrieval_time = time.time() - start_time
            logger.info(
                f"âœ… ä¸ºç”¨æˆ· {user_id or 'unknown'} æ£€ç´¢åˆ° {len(top_memories)} æ¡ç›¸å…³è®°å¿†ï¼Œè€—æ—¶ {retrieval_time:.3f}ç§’"
            )

            self.last_retrieval_time = time.time()
            self.status = MemorySystemStatus.READY

            return top_memories

        except Exception as e:
            self.status = MemorySystemStatus.ERROR
            logger.error(f"âŒ è®°å¿†æ£€ç´¢å¤±è´¥: {e}", exc_info=True)
            raise

    @staticmethod
    def _extract_json_payload(response: str) -> Optional[str]:
        """ä»æ¨¡å‹å“åº”ä¸­æå–JSONéƒ¨åˆ†ï¼Œå…¼å®¹Markdownä»£ç å—ç­‰æ ¼å¼"""
        if not response:
            return None

        stripped = response.strip()

        # ä¼˜å…ˆå¤„ç†Markdownä»£ç å—æ ¼å¼ ```json ... ```
        code_block_match = re.search(r"```(?:json)?\s*(.*?)```", stripped, re.IGNORECASE | re.DOTALL)
        if code_block_match:
            candidate = code_block_match.group(1).strip()
            if candidate:
                return candidate

        # å›é€€åˆ°æŸ¥æ‰¾ç¬¬ä¸€ä¸ª JSON å¯¹è±¡çš„å¤§æ‹¬å·èŒƒå›´
        start = stripped.find("{")
        end = stripped.rfind("}")
        if start != -1 and end != -1 and end > start:
            return stripped[start:end + 1].strip()

        return stripped if stripped.startswith("{") and stripped.endswith("}") else None

    def _normalize_context(
        self,
        raw_context: Optional[Dict[str, Any]],
        user_id: Optional[str],
        timestamp: Optional[float]
    ) -> Dict[str, Any]:
        """æ ‡å‡†åŒ–ä¸Šä¸‹æ–‡ï¼Œç¡®ä¿å¿…å¤‡å­—æ®µå­˜åœ¨ä¸”æ ¼å¼æ­£ç¡®"""
        context: Dict[str, Any] = {}
        if raw_context:
            try:
                context = dict(raw_context)
            except Exception:
                context = dict(raw_context or {})

        # åŸºç¡€å­—æ®µ
        context["user_id"] = context.get("user_id") or user_id or "unknown"
        context["timestamp"] = context.get("timestamp") or timestamp or time.time()
        context["message_type"] = context.get("message_type") or "normal"
        context["platform"] = context.get("platform") or context.get("source_platform") or "unknown"

        # æ ‡å‡†åŒ–å…³é”®è¯ç±»å‹
        keywords = context.get("keywords")
        if keywords is None:
            context["keywords"] = []
        elif isinstance(keywords, tuple):
            context["keywords"] = list(keywords)
        elif not isinstance(keywords, list):
            context["keywords"] = [str(keywords)] if keywords else []

        # ç»Ÿä¸€ stream_id
        stream_id = context.get("stream_id") or context.get("stram_id")
        if not stream_id:
            potential = context.get("chat_id") or context.get("session_id")
            if isinstance(potential, str) and potential:
                stream_id = potential
        if stream_id:
            context["stream_id"] = stream_id

        # chat_id å…œåº•
        context["chat_id"] = context.get("chat_id") or context.get("stream_id") or f"session_{context['user_id']}"

        # å†å²çª—å£é…ç½®
        window_candidate = (
            context.get("history_limit")
            or context.get("history_window")
            or context.get("memory_history_limit")
        )
        if window_candidate is not None:
            try:
                context["history_limit"] = int(window_candidate)
            except (TypeError, ValueError):
                context.pop("history_limit", None)

        return context

    def _resolve_conversation_context(self, fallback_text: str, context: Optional[Dict[str, Any]]) -> str:
        """ä½¿ç”¨ stream_id å†å²æ¶ˆæ¯å……å®å¯¹è¯æ–‡æœ¬ï¼Œé»˜è®¤å›é€€åˆ°ä¼ å…¥æ–‡æœ¬"""
        if not context:
            return fallback_text

        stream_id = context.get("stream_id") or context.get("stram_id")
        if not stream_id:
            return fallback_text

        try:
            from src.chat.message_receive.chat_stream import get_chat_manager

            chat_manager = get_chat_manager()
            chat_stream = chat_manager.get_stream(stream_id)
            if not chat_stream or not hasattr(chat_stream, "context_manager"):
                logger.debug(f"æœªæ‰¾åˆ° stream_id={stream_id} å¯¹åº”çš„èŠå¤©æµæˆ–ä¸Šä¸‹æ–‡ç®¡ç†å™¨")
                return fallback_text

            history_limit = self._determine_history_limit(context)
            messages = chat_stream.context_manager.get_messages(limit=history_limit, include_unread=True)
            if not messages:
                logger.debug(f"stream_id={stream_id} æœªè·å–åˆ°å†å²æ¶ˆæ¯")
                return fallback_text

            transcript = self._format_history_messages(messages)
            if not transcript:
                return fallback_text

            cleaned_fallback = (fallback_text or "").strip()
            if cleaned_fallback and cleaned_fallback not in transcript:
                transcript = f"{transcript}\n[å½“å‰æ¶ˆæ¯] {cleaned_fallback}"

            logger.debug(
                "ä½¿ç”¨ stream_id=%s çš„å†å²æ¶ˆæ¯æ„å»ºè®°å¿†ä¸Šä¸‹æ–‡ï¼Œæ¶ˆæ¯æ•°=%dï¼Œé™åˆ¶=%d",
                stream_id,
                len(messages),
                history_limit,
            )
            return transcript

        except Exception as exc:
            logger.warning(f"è·å– stream_id={stream_id} çš„å†å²æ¶ˆæ¯å¤±è´¥: {exc}", exc_info=True)
            return fallback_text

    def _get_build_scope_key(self, context: Dict[str, Any], user_id: Optional[str]) -> Optional[str]:
        """ç¡®å®šç”¨äºèŠ‚æµæ§åˆ¶çš„è®°å¿†æ„å»ºä½œç”¨åŸŸ"""
        stream_id = context.get("stream_id")
        if stream_id:
            return f"stream::{stream_id}"

        chat_id = context.get("chat_id")
        if chat_id:
            return f"chat::{chat_id}"

        if user_id:
            return f"user::{user_id}"

        return None

    def _determine_history_limit(self, context: Dict[str, Any]) -> int:
        """ç¡®å®šå†å²æ¶ˆæ¯è·å–æ•°é‡ï¼Œé™åˆ¶åœ¨30-50ä¹‹é—´"""
        default_limit = 40
        candidate = (
            context.get("history_limit")
            or context.get("history_window")
            or context.get("memory_history_limit")
        )

        if isinstance(candidate, str):
            try:
                candidate = int(candidate)
            except ValueError:
                candidate = None

        if isinstance(candidate, int):
            history_limit = max(30, min(50, candidate))
        else:
            history_limit = default_limit

        return history_limit

    def _format_history_messages(self, messages: List["DatabaseMessages"]) -> Optional[str]:
        """å°†å†å²æ¶ˆæ¯æ ¼å¼åŒ–ä¸ºå¯ä¾›LLMå¤„ç†çš„å¤šè½®å¯¹è¯æ–‡æœ¬"""
        if not messages:
            return None

        lines: List[str] = []
        for msg in messages:
            try:
                content = getattr(msg, "processed_plain_text", None) or getattr(msg, "display_message", None)
                if not content:
                    continue

                content = re.sub(r"\s+", " ", str(content).strip())
                if not content:
                    continue

                speaker = None
                if hasattr(msg, "user_info") and msg.user_info:
                    speaker = (
                        getattr(msg.user_info, "user_nickname", None)
                        or getattr(msg.user_info, "user_cardname", None)
                        or getattr(msg.user_info, "user_id", None)
                    )
                speaker = speaker or getattr(msg, "user_nickname", None) or getattr(msg, "user_id", None) or "ç”¨æˆ·"

                timestamp_value = getattr(msg, "time", None) or 0.0
                try:
                    timestamp_dt = datetime.fromtimestamp(float(timestamp_value)) if timestamp_value else datetime.now()
                except (TypeError, ValueError, OSError):
                    timestamp_dt = datetime.now()

                timestamp_str = timestamp_dt.strftime("%Y-%m-%d %H:%M:%S")
                lines.append(f"[{timestamp_str}] {speaker}: {content}")

            except Exception as message_exc:
                logger.debug(f"æ ¼å¼åŒ–å†å²æ¶ˆæ¯å¤±è´¥: {message_exc}")
                continue

        return "\n".join(lines) if lines else None

    async def _assess_information_value(self, text: str, context: Dict[str, Any]) -> float:
        """è¯„ä¼°ä¿¡æ¯ä»·å€¼

        Args:
            text: æ–‡æœ¬å†…å®¹
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯

        Returns:
            ä»·å€¼è¯„åˆ† (0.0-1.0)
        """
        try:
            # æ„å»ºè¯„ä¼°æç¤º
            prompt = f"""
è¯·è¯„ä¼°ä»¥ä¸‹å¯¹è¯å†…å®¹çš„ä¿¡æ¯ä»·å€¼ï¼Œé‡ç‚¹è¯†åˆ«åŒ…å«ä¸ªäººäº‹å®ã€äº‹ä»¶ã€åå¥½ã€è§‚ç‚¹ç­‰é‡è¦ä¿¡æ¯çš„å†…å®¹ã€‚

## ğŸ¯ ä»·å€¼è¯„ä¼°é‡ç‚¹æ ‡å‡†ï¼š

### é«˜ä»·å€¼ä¿¡æ¯ (0.7-1.0åˆ†)ï¼š
1. **ä¸ªäººäº‹å®** (personal_fact)ï¼šåŒ…å«å§“åã€å¹´é¾„ã€èŒä¸šã€è”ç³»æ–¹å¼ã€ä½å€ã€å¥åº·çŠ¶å†µã€å®¶åº­æƒ…å†µç­‰ä¸ªäººä¿¡æ¯
2. **é‡è¦äº‹ä»¶** (event)ï¼šçº¦ä¼šã€ä¼šè®®ã€æ—…è¡Œã€è€ƒè¯•ã€é¢è¯•ã€æ¬å®¶ç­‰é‡è¦æ´»åŠ¨æˆ–ç»å†
3. **æ˜ç¡®åå¥½** (preference)ï¼šè¡¨è¾¾å–œæ¬¢/ä¸å–œæ¬¢çš„é£Ÿç‰©ã€ç”µå½±ã€éŸ³ä¹ã€å“ç‰Œã€ç”Ÿæ´»ä¹ æƒ¯ç­‰åå¥½ä¿¡æ¯
4. **è§‚ç‚¹æ€åº¦** (opinion)ï¼šå¯¹äº‹ç‰©çš„è¯„ä»·ã€çœ‹æ³•ã€å»ºè®®ã€æ€åº¦ç­‰ä¸»è§‚è§‚ç‚¹
5. **æ ¸å¿ƒå…³ç³»** (relationship)ï¼šé‡è¦çš„æœ‹å‹ã€å®¶äººã€åŒäº‹ç­‰äººé™…å…³ç³»ä¿¡æ¯

### ä¸­ç­‰ä»·å€¼ä¿¡æ¯ (0.4-0.7åˆ†)ï¼š
1. **æƒ…æ„Ÿè¡¨è¾¾**ï¼šå½“å‰æƒ…ç»ªçŠ¶æ€ã€å¿ƒæƒ…å˜åŒ–
2. **æ—¥å¸¸æ´»åŠ¨**ï¼šå¸¸è§„çš„å·¥ä½œã€å­¦ä¹ ã€ç”Ÿæ´»å®‰æ’
3. **ä¸€èˆ¬å…´è¶£**ï¼šå…´è¶£çˆ±å¥½ã€ä¼‘é—²æ´»åŠ¨
4. **çŸ­æœŸè®¡åˆ’**ï¼šå³å°†è¿›è¡Œçš„å®‰æ’å’Œè®¡åˆ’

### ä½ä»·å€¼ä¿¡æ¯ (0.0-0.4åˆ†)ï¼š
1. **å¯’æš„é—®å€™**ï¼šç®€å•çš„æ‰“æ‹›å‘¼ã€ç¤¼è²Œç”¨è¯­
2. **é‡å¤ä¿¡æ¯**ï¼šå·²ç»å¤šæ¬¡æåˆ°çš„ç›¸åŒå†…å®¹
3. **ä¸´æ—¶çŠ¶æ€**ï¼šçŸ­æš‚çš„æƒ…ç»ªæ³¢åŠ¨ã€ä¸´æ—¶æƒ³æ³•
4. **æ— å…³å†…å®¹**ï¼šä¸ç”¨æˆ·ç”»åƒå»ºç«‹æ— å…³çš„ä¿¡æ¯

å¯¹è¯å†…å®¹ï¼š
{text}

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
- ç”¨æˆ·ID: {context.get('user_id', 'unknown')}
- æ¶ˆæ¯ç±»å‹: {context.get('message_type', 'unknown')}
- æ—¶é—´: {datetime.fromtimestamp(context.get('timestamp', time.time()))}

## ğŸ“‹ è¯„ä¼°è¦æ±‚ï¼š

### ç§¯æè¯†åˆ«åŸåˆ™ï¼š
- **å®å¯é«˜ä¼°ï¼Œä¸å¯ä½ä¼°** - å¯¹äºå¯èƒ½çš„ä¸ªäººä¿¡æ¯ç»™äºˆè¾ƒé«˜è¯„ä¼°
- **é‡ç‚¹å…³æ³¨** - ç‰¹åˆ«æ³¨æ„åŒ…å« personal_factã€eventã€preferenceã€opinion çš„å†…å®¹
- **ç»†èŠ‚ä¸°å¯Œ** - å…·ä½“çš„ç»†èŠ‚ä¿¡æ¯æ¯”ç¬¼ç»Ÿçš„æè¿°æ›´æœ‰ä»·å€¼
- **å»ºç«‹ç”»åƒ** - æœ‰åŠ©äºå»ºç«‹å®Œæ•´ç”¨æˆ·ç”»åƒçš„ä¿¡æ¯æ›´æœ‰ä»·å€¼

### è¯„åˆ†æŒ‡å¯¼ï¼š
- **0.9-1.0**ï¼šæ ¸å¿ƒä¸ªäººä¿¡æ¯ï¼ˆå§“åã€è”ç³»æ–¹å¼ã€é‡è¦åå¥½ï¼‰
- **0.7-0.8**ï¼šé‡è¦çš„ä¸ªäººäº‹å®ã€è§‚ç‚¹ã€äº‹ä»¶ç»å†
- **0.5-0.6**ï¼šä¸€èˆ¬æ€§åå¥½ã€æ—¥å¸¸æ´»åŠ¨ã€æƒ…æ„Ÿè¡¨è¾¾
- **0.3-0.4**ï¼šç®€å•çš„å…´è¶£è¡¨è¾¾ã€ä¸´æ—¶çŠ¶æ€
- **0.0-0.2**ï¼šå¯’æš„é—®å€™ã€é‡å¤å†…å®¹ã€æ— å…³ä¿¡æ¯

è¯·ä»¥JSONæ ¼å¼è¾“å‡ºè¯„ä¼°ç»“æœï¼š
{{
    "value_score": 0.0åˆ°1.0ä¹‹é—´çš„æ•°å€¼,
    "reasoning": "è¯„ä¼°ç†ç”±ï¼ŒåŒ…å«å…·ä½“è¯†åˆ«åˆ°çš„ä¿¡æ¯ç±»å‹",
    "key_factors": ["å…³é”®å› ç´ 1", "å…³é”®å› ç´ 2"],
    "detected_types": ["personal_fact", "preference", "opinion", "event", "relationship", "emotion", "goal"]
}}
"""

            response, _ = await self.value_assessment_model.generate_response_async(
                prompt, temperature=0.3
            )

            # è§£æå“åº”
            try:
                payload = self._extract_json_payload(response)
                if not payload:
                    raise ValueError("æœªåœ¨å“åº”ä¸­æ‰¾åˆ°æœ‰æ•ˆçš„JSONè´Ÿè½½")

                result = orjson.loads(payload)
                value_score = float(result.get("value_score", 0.0))
                reasoning = result.get("reasoning", "")
                key_factors = result.get("key_factors", [])

                logger.info(f"ä¿¡æ¯ä»·å€¼è¯„ä¼°: {value_score:.2f}, ç†ç”±: {reasoning}")
                if key_factors:
                    logger.info(f"å…³é”®å› ç´ : {', '.join(key_factors)}")

                return max(0.0, min(1.0, value_score))

            except (orjson.JSONDecodeError, ValueError) as e:
                preview = response[:200].replace('\n', ' ')
                logger.warning(f"è§£æä»·å€¼è¯„ä¼°å“åº”å¤±è´¥: {e}, å“åº”ç‰‡æ®µ: {preview}")
                return 0.5  # é»˜è®¤ä¸­ç­‰ä»·å€¼

        except Exception as e:
            logger.error(f"ä¿¡æ¯ä»·å€¼è¯„ä¼°å¤±è´¥: {e}", exc_info=True)
            return 0.5  # é»˜è®¤ä¸­ç­‰ä»·å€¼

    async def _store_memories(self, memory_chunks: List[MemoryChunk]):
        """å­˜å‚¨è®°å¿†å—åˆ°å„ä¸ªå­˜å‚¨ç³»ç»Ÿ"""
        if not memory_chunks:
            return

        # å¹¶è¡Œå­˜å‚¨åˆ°å‘é‡æ•°æ®åº“å’Œå…ƒæ•°æ®ç´¢å¼•
        storage_tasks = []

        # å‘é‡å­˜å‚¨
        storage_tasks.append(self.vector_storage.store_memories(memory_chunks))

        # å…ƒæ•°æ®ç´¢å¼•
        storage_tasks.append(self.metadata_index.index_memories(memory_chunks))

        # ç­‰å¾…æ‰€æœ‰å­˜å‚¨ä»»åŠ¡å®Œæˆ
        await asyncio.gather(*storage_tasks, return_exceptions=True)

        logger.debug(f"æˆåŠŸå­˜å‚¨ {len(memory_chunks)} æ¡è®°å¿†åˆ°å„ä¸ªå­˜å‚¨ç³»ç»Ÿ")

    def get_system_stats(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        return {
            "status": self.status.value,
            "total_memories": self.total_memories,
            "last_build_time": self.last_build_time,
            "last_retrieval_time": self.last_retrieval_time,
            "config": asdict(self.config)
        }

    def _compute_memory_score(self, query_text: str, memory: MemoryChunk, context: Dict[str, Any]) -> float:
        """æ ¹æ®æŸ¥è¯¢å’Œä¸Šä¸‹æ–‡ä¸ºè®°å¿†è®¡ç®—åŒ¹é…åˆ†æ•°"""
        tokens_query = self._tokenize_text(query_text)
        tokens_memory = self._tokenize_text(memory.text_content)

        if tokens_query and tokens_memory:
            base_score = len(tokens_query & tokens_memory) / len(tokens_query | tokens_memory)
        else:
            base_score = 0.0

        context_keywords = context.get("keywords") or []
        keyword_overlap = 0.0
        if context_keywords:
            memory_keywords = set(k.lower() for k in memory.keywords)
            keyword_overlap = len(memory_keywords & set(k.lower() for k in context_keywords)) / max(len(context_keywords), 1)

        importance_boost = (memory.metadata.importance.value - 1) / 3 * 0.1
        confidence_boost = (memory.metadata.confidence.value - 1) / 3 * 0.05

        final_score = base_score * 0.7 + keyword_overlap * 0.15 + importance_boost + confidence_boost
        return max(0.0, min(1.0, final_score))

    def _tokenize_text(self, text: str) -> Set[str]:
        """ç®€å•åˆ†è¯ï¼Œå…¼å®¹ä¸­è‹±æ–‡"""
        if not text:
            return set()

        tokens = re.findall(r"[\w\u4e00-\u9fa5]+", text.lower())
        return {token for token in tokens if len(token) > 1}

    async def maintenance(self):
        """ç³»ç»Ÿç»´æŠ¤æ“ä½œ"""
        try:
            logger.info("å¼€å§‹è®°å¿†ç³»ç»Ÿç»´æŠ¤...")

            # å‘é‡å­˜å‚¨ä¼˜åŒ–
            await self.vector_storage.optimize_storage()

            # å…ƒæ•°æ®ç´¢å¼•ä¼˜åŒ–
            await self.metadata_index.optimize_index()

            # è®°å¿†èåˆå¼•æ“ç»´æŠ¤
            await self.fusion_engine.maintenance()

            logger.info("âœ… è®°å¿†ç³»ç»Ÿç»´æŠ¤å®Œæˆ")

        except Exception as e:
            logger.error(f"âŒ è®°å¿†ç³»ç»Ÿç»´æŠ¤å¤±è´¥: {e}", exc_info=True)

    async def shutdown(self):
        """å…³é—­ç³»ç»Ÿ"""
        try:
            logger.info("æ­£åœ¨å…³é—­å¢å¼ºå‹è®°å¿†ç³»ç»Ÿ...")

            # ä¿å­˜æŒä¹…åŒ–æ•°æ®
            await self.vector_storage.save_storage()
            await self.metadata_index.save_index()

            logger.info("âœ… å¢å¼ºå‹è®°å¿†ç³»ç»Ÿå·²å…³é—­")

        except Exception as e:
            logger.error(f"âŒ è®°å¿†ç³»ç»Ÿå…³é—­å¤±è´¥: {e}", exc_info=True)


# å…¨å±€è®°å¿†ç³»ç»Ÿå®ä¾‹
enhanced_memory_system: EnhancedMemorySystem = None


def get_enhanced_memory_system() -> EnhancedMemorySystem:
    """è·å–å…¨å±€è®°å¿†ç³»ç»Ÿå®ä¾‹"""
    global enhanced_memory_system
    if enhanced_memory_system is None:
        enhanced_memory_system = EnhancedMemorySystem()
    return enhanced_memory_system


async def initialize_enhanced_memory_system():
    """åˆå§‹åŒ–å…¨å±€è®°å¿†ç³»ç»Ÿ"""
    global enhanced_memory_system
    if enhanced_memory_system is None:
        enhanced_memory_system = EnhancedMemorySystem()
    await enhanced_memory_system.initialize()
    return enhanced_memory_system